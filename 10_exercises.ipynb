{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 10\n",
    "Train a deep MLP on the MNIST dataset (you can load it using tf.keras.​data⁠sets.mnist.load_data()). See if you can get over 98% accuracy by manually tuning the hyperparameters. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Next, try tuning the hyperparameters using Keras Tuner with all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5000.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [5000.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [5000.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [5000.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [5000.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [5000.,    0.,    0., ...,    0.,    0.,    0.]]),\n",
       " array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,\n",
       "        0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,\n",
       "        0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 , 0.62, 0.64,\n",
       "        0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.84, 0.86,\n",
       "        0.88, 0.9 , 0.92, 0.94, 0.96, 0.98, 1.  ]),\n",
       " <a list of 784 BarContainer objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_valid.reshape(5000, -1), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1307167506093348, 0.30819664165272803)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train), np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.98395722e-06, 3.35115865e-05, 1.54010695e-05, 6.41711230e-07,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.14081996e-06, 3.92156863e-06, 3.97147950e-05, 9.86809269e-05,\n",
       "        1.41818182e-04, 2.07985740e-04, 4.09982175e-04, 5.71978610e-04,\n",
       "        6.28663102e-04, 6.40213904e-04, 7.15008913e-04, 6.78716578e-04,\n",
       "        7.01105169e-04, 5.37754011e-04, 3.52014260e-04, 2.46844920e-04,\n",
       "        2.08342246e-04, 9.06238859e-05, 4.31372549e-05, 1.51158645e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.56327986e-06, 2.06773619e-06,\n",
       "        2.81639929e-05, 2.03208556e-05, 1.72762923e-04, 5.11016043e-04,\n",
       "        1.02509804e-03, 1.96192513e-03, 3.35871658e-03, 5.00370766e-03,\n",
       "        7.38103387e-03, 9.93155080e-03, 1.23695544e-02, 1.39335472e-02,\n",
       "        1.41813904e-02, 1.30003565e-02, 1.07730481e-02, 7.89711230e-03,\n",
       "        4.66916221e-03, 2.39992870e-03, 1.10709447e-03, 3.88877005e-04,\n",
       "        1.50659537e-04, 3.69340463e-05, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.08377897e-05, 1.57575758e-05,\n",
       "        3.69340463e-05, 2.71942959e-04, 8.49910873e-04, 2.16178253e-03,\n",
       "        4.58581105e-03, 8.76748663e-03, 1.43710517e-02, 2.13832442e-02,\n",
       "        2.91034581e-02, 3.80628877e-02, 4.64479857e-02, 5.14092692e-02,\n",
       "        5.09106595e-02, 4.59632086e-02, 3.73200713e-02, 2.68258824e-02,\n",
       "        1.63078788e-02, 8.80677362e-03, 4.17276292e-03, 1.71515152e-03,\n",
       "        6.92335116e-04, 1.18645276e-04, 1.19786096e-05, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.70944742e-06, 1.04812834e-05, 4.22816399e-05,\n",
       "        3.08235294e-04, 1.63108734e-03, 4.19301248e-03, 9.63914439e-03,\n",
       "        1.89947950e-02, 3.33720499e-02, 5.28168271e-02, 7.69301248e-02,\n",
       "        1.06563636e-01, 1.38335686e-01, 1.63732906e-01, 1.76886061e-01,\n",
       "        1.73463957e-01, 1.52804563e-01, 1.22171266e-01, 8.91686275e-02,\n",
       "        5.77269162e-02, 3.36277362e-02, 1.76330838e-02, 8.30445633e-03,\n",
       "        3.36171123e-03, 8.47843137e-04, 1.26844920e-04, 8.69875223e-06],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.67201426e-05, 2.32941176e-04,\n",
       "        1.58374332e-03, 5.87828877e-03, 1.43449554e-02, 2.86917647e-02,\n",
       "        5.15525847e-02, 8.38417825e-02, 1.24330553e-01, 1.74003209e-01,\n",
       "        2.31539109e-01, 2.89803494e-01, 3.33547308e-01, 3.54781961e-01,\n",
       "        3.48024599e-01, 3.13068806e-01, 2.56628734e-01, 1.93229162e-01,\n",
       "        1.33293191e-01, 8.31931551e-02, 4.76991087e-02, 2.55347594e-02,\n",
       "        1.16556863e-02, 3.35151515e-03, 5.69340463e-04, 2.01069519e-05],\n",
       "       [0.00000000e+00, 7.84313725e-07, 1.11158645e-04, 8.78360071e-04,\n",
       "        4.49183601e-03, 1.31010339e-02, 2.94916221e-02, 5.62936185e-02,\n",
       "        9.55077362e-02, 1.47184884e-01, 2.08943815e-01, 2.78485490e-01,\n",
       "        3.50440143e-01, 4.16877861e-01, 4.64960357e-01, 4.86911943e-01,\n",
       "        4.76944314e-01, 4.38624884e-01, 3.75414474e-01, 2.92818253e-01,\n",
       "        2.10012050e-01, 1.36987736e-01, 8.13177184e-02, 4.41503743e-02,\n",
       "        2.08842781e-02, 7.25960784e-03, 1.44363636e-03, 1.29625668e-04],\n",
       "       [3.35115865e-06, 8.44206774e-05, 4.10124777e-04, 2.33625668e-03,\n",
       "        9.08171123e-03, 2.33040998e-02, 4.89475936e-02, 8.85396078e-02,\n",
       "        1.43320998e-01, 2.12321640e-01, 2.89978396e-01, 3.69265597e-01,\n",
       "        4.37202995e-01, 4.90112228e-01, 5.21355508e-01, 5.32354082e-01,\n",
       "        5.23834153e-01, 4.96970838e-01, 4.44785954e-01, 3.66100606e-01,\n",
       "        2.71937897e-01, 1.82536471e-01, 1.09706595e-01, 5.92673797e-02,\n",
       "        2.76130481e-02, 1.01853119e-02, 2.00591800e-03, 1.36399287e-04],\n",
       "       [1.36185383e-05, 2.04919786e-04, 1.27080214e-03, 5.06338681e-03,\n",
       "        1.44327986e-02, 3.30534759e-02, 6.59850980e-02, 1.16472228e-01,\n",
       "        1.84982888e-01, 2.68431087e-01, 3.54953654e-01, 4.25382531e-01,\n",
       "        4.67851836e-01, 4.84407415e-01, 4.83952014e-01, 4.82106025e-01,\n",
       "        4.83379608e-01, 4.80722923e-01, 4.56135544e-01, 3.93212549e-01,\n",
       "        3.01571052e-01, 2.06494046e-01, 1.24654332e-01, 6.43312656e-02,\n",
       "        2.83721212e-02, 1.02670232e-02, 1.87579323e-03, 1.16292335e-04],\n",
       "       [7.70053476e-06, 3.21426025e-04, 2.03572193e-03, 6.61433155e-03,\n",
       "        1.71079501e-02, 3.81380392e-02, 7.65285561e-02, 1.35552086e-01,\n",
       "        2.15386524e-01, 3.07492692e-01, 3.88891408e-01, 4.32925704e-01,\n",
       "        4.33664742e-01, 4.10341248e-01, 3.90407130e-01, 3.92336328e-01,\n",
       "        4.11619251e-01, 4.36911943e-01, 4.35925348e-01, 3.87805276e-01,\n",
       "        3.00681783e-01, 2.05934688e-01, 1.23518289e-01, 6.07159358e-02,\n",
       "        2.36696613e-02, 7.54752228e-03, 1.42210339e-03, 1.12655971e-04],\n",
       "       [1.32620321e-05, 3.72192513e-04, 2.01739750e-03, 6.36998217e-03,\n",
       "        1.65639216e-02, 3.84699465e-02, 8.04141176e-02, 1.46104029e-01,\n",
       "        2.34684777e-01, 3.27511373e-01, 3.92794439e-01, 4.03403209e-01,\n",
       "        3.67692834e-01, 3.26472157e-01, 3.13837647e-01, 3.33868948e-01,\n",
       "        3.70701676e-01, 4.11302816e-01, 4.16329911e-01, 3.68559073e-01,\n",
       "        2.80975045e-01, 1.88970553e-01, 1.11666096e-01, 5.31195722e-02,\n",
       "        1.82390731e-02, 4.61575758e-03, 9.20285205e-04, 7.12299465e-05],\n",
       "       [2.37433155e-05, 2.70089127e-04, 1.60762923e-03, 4.89212121e-03,\n",
       "        1.41552941e-02, 3.74156863e-02, 8.31598574e-02, 1.57053048e-01,\n",
       "        2.51911729e-01, 3.41924064e-01, 3.86658396e-01, 3.71019037e-01,\n",
       "        3.20760143e-01, 2.89335258e-01, 3.00659964e-01, 3.36945668e-01,\n",
       "        3.83249198e-01, 4.22378824e-01, 4.13017326e-01, 3.48247558e-01,\n",
       "        2.54212193e-01, 1.66414902e-01, 9.91893761e-02, 4.93972906e-02,\n",
       "        1.56601070e-02, 2.35679144e-03, 5.00891266e-04, 3.49376114e-05],\n",
       "       [1.62566845e-05, 1.78324421e-04, 9.21426025e-04, 3.41654189e-03,\n",
       "        1.20658824e-02, 3.79721925e-02, 8.99667736e-02, 1.71652763e-01,\n",
       "        2.70650909e-01, 3.53324991e-01, 3.83014617e-01, 3.56848128e-01,\n",
       "        3.12976328e-01, 3.12844706e-01, 3.51925704e-01, 4.00059037e-01,\n",
       "        4.43964207e-01, 4.61158075e-01, 4.20329198e-01, 3.30791159e-01,\n",
       "        2.29937897e-01, 1.50381105e-01, 9.30838503e-02, 4.99644207e-02,\n",
       "        1.69500891e-02, 1.76705882e-03, 3.25204991e-04, 4.34937611e-05],\n",
       "       [2.28163993e-06, 7.80748663e-05, 4.47486631e-04, 2.39315508e-03,\n",
       "        1.15506595e-02, 4.20071301e-02, 1.00561640e-01, 1.86960784e-01,\n",
       "        2.84604064e-01, 3.58844777e-01, 3.80054973e-01, 3.58123422e-01,\n",
       "        3.41692977e-01, 3.81849412e-01, 4.37834439e-01, 4.87168841e-01,\n",
       "        5.09509875e-01, 4.95258538e-01, 4.25533405e-01, 3.17821176e-01,\n",
       "        2.16812549e-01, 1.46200784e-01, 9.42628877e-02, 5.36248128e-02,\n",
       "        2.01375401e-02, 2.32563280e-03, 3.01319073e-04, 4.64884135e-05],\n",
       "       [8.05704100e-06, 3.52941176e-05, 1.89447415e-04, 1.79522282e-03,\n",
       "        1.21277005e-02, 4.86246702e-02, 1.11905027e-01, 1.98376827e-01,\n",
       "        2.89026096e-01, 3.54215686e-01, 3.73688342e-01, 3.67180820e-01,\n",
       "        3.84751230e-01, 4.54079786e-01, 5.12503957e-01, 5.48867023e-01,\n",
       "        5.38142816e-01, 5.01035009e-01, 4.18499465e-01, 3.11524777e-01,\n",
       "        2.20164848e-01, 1.52714439e-01, 1.00292620e-01, 5.75401783e-02,\n",
       "        2.24946168e-02, 3.26017825e-03, 3.60641711e-04, 9.48306595e-06],\n",
       "       [3.13725490e-06, 1.65418895e-05, 1.66773619e-04, 2.01204991e-03,\n",
       "        1.40185383e-02, 5.65035294e-02, 1.21545241e-01, 2.00757790e-01,\n",
       "        2.80128128e-01, 3.36196720e-01, 3.59062317e-01, 3.70280000e-01,\n",
       "        4.12562210e-01, 4.84250909e-01, 5.33533119e-01, 5.47303387e-01,\n",
       "        5.17164349e-01, 4.75673369e-01, 3.96709590e-01, 3.07123708e-01,\n",
       "        2.28557219e-01, 1.61681355e-01, 1.06106595e-01, 5.86658111e-02,\n",
       "        2.30771480e-02, 4.35771836e-03, 6.11265597e-04, 4.02852050e-05],\n",
       "       [2.85204991e-06, 1.69696970e-05, 2.94260250e-04, 2.48213904e-03,\n",
       "        1.74694474e-02, 6.44176827e-02, 1.27379251e-01, 1.95535187e-01,\n",
       "        2.60064599e-01, 3.05780392e-01, 3.28929127e-01, 3.51227950e-01,\n",
       "        3.97204278e-01, 4.55667166e-01, 4.97538039e-01, 5.00842282e-01,\n",
       "        4.75136114e-01, 4.36271087e-01, 3.73669661e-01, 3.03053119e-01,\n",
       "        2.33562424e-01, 1.64928984e-01, 1.05172549e-01, 5.62263815e-02,\n",
       "        2.23690553e-02, 5.16805704e-03, 7.78181818e-04, 4.01426025e-05],\n",
       "       [0.00000000e+00, 3.11586453e-05, 4.69019608e-04, 3.78024955e-03,\n",
       "        2.30891266e-02, 7.21401070e-02, 1.31067308e-01, 1.88693476e-01,\n",
       "        2.37483351e-01, 2.72188235e-01, 2.93985811e-01, 3.17449626e-01,\n",
       "        3.52071515e-01, 4.01005134e-01, 4.42981818e-01, 4.53296898e-01,\n",
       "        4.40539394e-01, 4.10341176e-01, 3.63073654e-01, 3.02532549e-01,\n",
       "        2.32285062e-01, 1.59854759e-01, 9.78549020e-02, 5.04674510e-02,\n",
       "        2.04634581e-02, 5.62360071e-03, 8.55115865e-04, 3.73618538e-05],\n",
       "       [8.12834225e-06, 2.27450980e-05, 7.21140820e-04, 6.06559715e-03,\n",
       "        2.94952585e-02, 7.94204635e-02, 1.36917504e-01, 1.89196720e-01,\n",
       "        2.29231373e-01, 2.59786381e-01, 2.82464314e-01, 3.01364848e-01,\n",
       "        3.27385882e-01, 3.74990588e-01, 4.19036150e-01, 4.40088627e-01,\n",
       "        4.36520713e-01, 4.11969055e-01, 3.67055116e-01, 3.00261176e-01,\n",
       "        2.22134046e-01, 1.47924777e-01, 8.83814617e-02, 4.44978966e-02,\n",
       "        1.80221034e-02, 5.09490196e-03, 5.90017825e-04, 5.21212121e-05],\n",
       "       [1.06951872e-06, 4.52049911e-05, 1.13711230e-03, 8.07436720e-03,\n",
       "        3.37687701e-02, 8.44169697e-02, 1.44076791e-01, 1.99761640e-01,\n",
       "        2.44599643e-01, 2.80026524e-01, 3.05985526e-01, 3.24881925e-01,\n",
       "        3.53848128e-01, 3.98467023e-01, 4.40518645e-01, 4.60699679e-01,\n",
       "        4.53915009e-01, 4.21229020e-01, 3.61868806e-01, 2.82150873e-01,\n",
       "        1.99420321e-01, 1.28269875e-01, 7.34240998e-02, 3.56019251e-02,\n",
       "        1.41423886e-02, 4.15393939e-03, 5.16648841e-04, 2.92335116e-05],\n",
       "       [0.00000000e+00, 6.53119430e-05, 1.30766488e-03, 8.85860963e-03,\n",
       "        3.28790731e-02, 8.02899822e-02, 1.44288342e-01, 2.09802781e-01,\n",
       "        2.69294474e-01, 3.17980677e-01, 3.54599216e-01, 3.84118574e-01,\n",
       "        4.18687201e-01, 4.59678859e-01, 4.88493405e-01, 4.91242353e-01,\n",
       "        4.63651123e-01, 4.08120642e-01, 3.30161070e-01, 2.41215187e-01,\n",
       "        1.61023316e-01, 9.80062745e-02, 5.32256684e-02, 2.53918717e-02,\n",
       "        1.03621390e-02, 2.87864528e-03, 4.01283422e-04, 7.20142602e-06],\n",
       "       [2.28163993e-06, 5.43315508e-05, 1.15172906e-03, 7.16235294e-03,\n",
       "        2.57115865e-02, 6.53834581e-02, 1.27430232e-01, 2.00567130e-01,\n",
       "        2.74634367e-01, 3.41124278e-01, 3.95530624e-01, 4.40984670e-01,\n",
       "        4.80485062e-01, 5.10356506e-01, 5.16112585e-01, 4.90246774e-01,\n",
       "        4.33458111e-01, 3.53503030e-01, 2.63167487e-01, 1.79889269e-01,\n",
       "        1.12596007e-01, 6.41870945e-02, 3.34342959e-02, 1.59981462e-02,\n",
       "        6.56263815e-03, 1.71515152e-03, 2.23885918e-04, 2.78074866e-06],\n",
       "       [2.21033868e-06, 4.20677362e-06, 7.57290553e-04, 4.29140820e-03,\n",
       "        1.54962567e-02, 4.21696257e-02, 9.09683422e-02, 1.57818752e-01,\n",
       "        2.37360642e-01, 3.16176114e-01, 3.87613191e-01, 4.42820036e-01,\n",
       "        4.79574474e-01, 4.90700463e-01, 4.73535615e-01, 4.22796649e-01,\n",
       "        3.46864528e-01, 2.61181889e-01, 1.79422816e-01, 1.13707594e-01,\n",
       "        6.68459893e-02, 3.63609982e-02, 1.86300891e-02, 8.65754011e-03,\n",
       "        3.25725490e-03, 7.36185383e-04, 7.54367201e-05, 5.13368984e-06],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.55971480e-04, 1.64898396e-03,\n",
       "        6.86730838e-03, 1.97052406e-02, 4.71150802e-02, 9.33721925e-02,\n",
       "        1.56984742e-01, 2.29556578e-01, 3.01501961e-01, 3.59215330e-01,\n",
       "        3.89204492e-01, 3.87583815e-01, 3.55733547e-01, 2.98721640e-01,\n",
       "        2.27993440e-01, 1.59322210e-01, 1.01195651e-01, 6.04507665e-02,\n",
       "        3.39847415e-02, 1.77604991e-02, 8.81518717e-03, 3.86039216e-03,\n",
       "        1.17860963e-03, 2.21675579e-04, 4.11408200e-05, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 6.71657754e-05, 4.96114082e-04,\n",
       "        2.16620321e-03, 6.36320856e-03, 1.65643494e-02, 3.57590018e-02,\n",
       "        6.56899109e-02, 1.05544385e-01, 1.48337112e-01, 1.82725134e-01,\n",
       "        2.00527273e-01, 1.98872014e-01, 1.78784314e-01, 1.45313369e-01,\n",
       "        1.08792299e-01, 7.56415686e-02, 4.79838146e-02, 2.86610339e-02,\n",
       "        1.57403209e-02, 8.02160428e-03, 3.82360071e-03, 1.60406417e-03,\n",
       "        3.95935829e-04, 9.17647059e-05, 8.27094474e-06, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 6.70231729e-06, 7.60784314e-05,\n",
       "        5.17361854e-04, 1.90823529e-03, 5.57561497e-03, 1.25180749e-02,\n",
       "        2.42198217e-02, 3.87130125e-02, 5.41546524e-02, 6.45317647e-02,\n",
       "        6.98678788e-02, 6.93092335e-02, 6.22161854e-02, 5.18810695e-02,\n",
       "        4.14449911e-02, 3.06060606e-02, 2.05005348e-02, 1.25080927e-02,\n",
       "        6.69026738e-03, 3.34438503e-03, 1.50438503e-03, 5.81176471e-04,\n",
       "        1.30196078e-04, 1.52584670e-05, 7.41532977e-06, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.70944742e-06,\n",
       "        1.41390374e-04, 6.41140820e-04, 2.05939394e-03, 4.56206774e-03,\n",
       "        9.04463458e-03, 1.36363636e-02, 1.84983957e-02, 2.26426381e-02,\n",
       "        2.45848841e-02, 2.41597148e-02, 2.17224955e-02, 1.75329768e-02,\n",
       "        1.39371123e-02, 1.00804991e-02, 6.56991087e-03, 3.97996435e-03,\n",
       "        2.16221034e-03, 9.79180036e-04, 3.17433155e-04, 6.31016043e-05,\n",
       "        2.21033868e-06, 4.20677362e-06, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.08377897e-05, 6.08912656e-05, 1.58288770e-04, 3.57361854e-04,\n",
       "        4.91693405e-04, 6.84064171e-04, 1.15900178e-03, 1.52292335e-03,\n",
       "        1.99065954e-03, 2.19237077e-03, 2.69518717e-03, 2.29803922e-03,\n",
       "        1.73853832e-03, 1.16606061e-03, 7.29197861e-04, 3.41247772e-04,\n",
       "        1.86737968e-04, 8.24955437e-05, 6.46702317e-05, 8.55614973e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.94688201e-03, 5.57530126e-03, 3.61183812e-03, 1.50493255e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.67543565e-04, 7.97210368e-04, 4.32121725e-03, 8.53981047e-03,\n",
       "        1.03521454e-02, 1.18338348e-02, 1.75311134e-02, 2.06973457e-02,\n",
       "        2.13554433e-02, 2.10812220e-02, 2.30466313e-02, 2.25100121e-02,\n",
       "        2.30455722e-02, 2.00312209e-02, 1.64685665e-02, 1.33621591e-02,\n",
       "        1.26134793e-02, 7.95653546e-03, 4.96112164e-03, 3.30366086e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.07017426e-03, 4.84922711e-04,\n",
       "        3.31991272e-03, 1.72350584e-03, 1.01227067e-02, 1.90835947e-02,\n",
       "        2.78767734e-02, 3.77164912e-02, 5.01207964e-02, 6.03390951e-02,\n",
       "        7.40680314e-02, 8.63225563e-02, 9.64914845e-02, 1.01543478e-01,\n",
       "        1.03460284e-01, 9.97377645e-02, 9.03490558e-02, 7.80322762e-02,\n",
       "        5.97008145e-02, 4.27240044e-02, 2.84652136e-02, 1.61037596e-02,\n",
       "        1.02385489e-02, 4.51567846e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.36488826e-03, 2.08545626e-03,\n",
       "        2.86750862e-03, 1.21445457e-02, 2.38567522e-02, 3.89533454e-02,\n",
       "        5.76000440e-02, 8.09875302e-02, 1.04334446e-01, 1.27776387e-01,\n",
       "        1.48186305e-01, 1.69508904e-01, 1.87162807e-01, 1.97067469e-01,\n",
       "        1.94833167e-01, 1.86269926e-01, 1.68516830e-01, 1.43542132e-01,\n",
       "        1.10800214e-01, 8.18623670e-02, 5.42457275e-02, 3.54447576e-02,\n",
       "        2.19798984e-02, 7.46188631e-03, 2.17056009e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 6.35415966e-04, 1.28142723e-03, 3.18864358e-03,\n",
       "        1.29699158e-02, 3.21094265e-02, 5.24608980e-02, 8.22731791e-02,\n",
       "        1.16889863e-01, 1.56387922e-01, 1.96608451e-01, 2.35192308e-01,\n",
       "        2.72230810e-01, 3.05531879e-01, 3.27958497e-01, 3.38531663e-01,\n",
       "        3.35529564e-01, 3.18461823e-01, 2.89843681e-01, 2.51174765e-01,\n",
       "        2.04604632e-01, 1.56014926e-01, 1.12027667e-01, 7.67274973e-02,\n",
       "        4.76670469e-02, 2.14668294e-02, 8.52093471e-03, 1.44327378e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.24365808e-03, 1.09821865e-02,\n",
       "        2.99146063e-02, 6.41388387e-02, 1.01864885e-01, 1.44900913e-01,\n",
       "        1.93996298e-01, 2.45074486e-01, 2.93004688e-01, 3.36821209e-01,\n",
       "        3.75164338e-01, 4.04401053e-01, 4.20090330e-01, 4.25067175e-01,\n",
       "        4.22942629e-01, 4.11691703e-01, 3.86885251e-01, 3.49497429e-01,\n",
       "        2.99801073e-01, 2.41281584e-01, 1.84311127e-01, 1.35515455e-01,\n",
       "        8.94183794e-02, 4.46223970e-02, 1.75016686e-02, 2.34511796e-03],\n",
       "       [0.00000000e+00, 1.34811768e-04, 7.10479798e-03, 2.40072092e-02,\n",
       "        5.64428803e-02, 9.77824222e-02, 1.47388511e-01, 2.03548254e-01,\n",
       "        2.61438030e-01, 3.16692656e-01, 3.62632682e-01, 3.97888151e-01,\n",
       "        4.22216404e-01, 4.34978621e-01, 4.39577059e-01, 4.40299012e-01,\n",
       "        4.40382876e-01, 4.39810215e-01, 4.30708112e-01, 4.06138985e-01,\n",
       "        3.63802466e-01, 3.04859893e-01, 2.41242198e-01, 1.78841307e-01,\n",
       "        1.21436726e-01, 6.97849204e-02, 3.01974652e-02, 8.43797622e-03],\n",
       "       [7.85909221e-04, 6.10883116e-03, 1.58404230e-02, 3.94559194e-02,\n",
       "        8.02168579e-02, 1.30615285e-01, 1.89079472e-01, 2.51470769e-01,\n",
       "        3.11004670e-01, 3.62431632e-01, 3.99143676e-01, 4.21304090e-01,\n",
       "        4.31094116e-01, 4.32752168e-01, 4.33222549e-01, 4.31965430e-01,\n",
       "        4.32153558e-01, 4.34002488e-01, 4.35342447e-01, 4.26054423e-01,\n",
       "        3.95638124e-01, 3.43958166e-01, 2.77117364e-01, 2.06727182e-01,\n",
       "        1.40269799e-01, 8.38494364e-02, 3.55834868e-02, 8.48507480e-03],\n",
       "       [3.19380130e-03, 1.18286772e-02, 2.98198821e-02, 6.01039569e-02,\n",
       "        1.04169228e-01, 1.57137901e-01, 2.19809187e-01, 2.85336908e-01,\n",
       "        3.46005394e-01, 3.93024245e-01, 4.20737181e-01, 4.33151380e-01,\n",
       "        4.35894270e-01, 4.36851850e-01, 4.36117601e-01, 4.34563703e-01,\n",
       "        4.34532510e-01, 4.35618262e-01, 4.37145287e-01, 4.32094710e-01,\n",
       "        4.09845189e-01, 3.63093683e-01, 2.94583864e-01, 2.15337010e-01,\n",
       "        1.43188462e-01, 8.48470847e-02, 3.49248024e-02, 8.24406007e-03],\n",
       "       [1.38797423e-03, 1.50979559e-02, 3.81996064e-02, 7.20107057e-02,\n",
       "        1.14744748e-01, 1.69067716e-01, 2.36606284e-01, 3.06246610e-01,\n",
       "        3.67477413e-01, 4.09767708e-01, 4.31487096e-01, 4.37207291e-01,\n",
       "        4.36734046e-01, 4.31900416e-01, 4.27820432e-01, 4.26821509e-01,\n",
       "        4.29064452e-01, 4.33962337e-01, 4.35982097e-01, 4.31301731e-01,\n",
       "        4.09897950e-01, 3.63927640e-01, 2.93963897e-01, 2.08690861e-01,\n",
       "        1.29584920e-01, 7.13542502e-02, 2.97796703e-02, 7.95760693e-03],\n",
       "       [3.09351736e-03, 1.66019932e-02, 3.85687767e-02, 7.00818389e-02,\n",
       "        1.13100487e-01, 1.69725965e-01, 2.41911200e-01, 3.15194855e-01,\n",
       "        3.78532724e-01, 4.17271296e-01, 4.32890171e-01, 4.34470889e-01,\n",
       "        4.23392930e-01, 4.08576653e-01, 4.04946561e-01, 4.13081406e-01,\n",
       "        4.21686708e-01, 4.30944992e-01, 4.33030910e-01, 4.28059812e-01,\n",
       "        4.01548036e-01, 3.52515031e-01, 2.81613211e-01, 1.95437059e-01,\n",
       "        1.13836942e-01, 5.61749853e-02, 2.42456645e-02, 6.11510653e-03],\n",
       "       [3.42311648e-03, 1.31313112e-02, 3.45904097e-02, 6.01189532e-02,\n",
       "        1.03530254e-01, 1.66098758e-01, 2.45215634e-01, 3.24309213e-01,\n",
       "        3.88159157e-01, 4.22416570e-01, 4.32352436e-01, 4.26671207e-01,\n",
       "        4.08230286e-01, 3.93419201e-01, 4.03896338e-01, 4.17887099e-01,\n",
       "        4.23877773e-01, 4.31559301e-01, 4.32969156e-01, 4.23107820e-01,\n",
       "        3.88241236e-01, 3.33508603e-01, 2.68665936e-01, 1.90943337e-01,\n",
       "        1.04553746e-01, 3.85169956e-02, 1.78249204e-02, 3.66572322e-03],\n",
       "       [2.93430236e-03, 1.08878873e-02, 2.58476977e-02, 5.00520685e-02,\n",
       "        9.47295551e-02, 1.67241798e-01, 2.54450459e-01, 3.37483321e-01,\n",
       "        3.98203231e-01, 4.27295125e-01, 4.31971984e-01, 4.24447827e-01,\n",
       "        4.08019248e-01, 4.04721814e-01, 4.27452850e-01, 4.34529029e-01,\n",
       "        4.31022191e-01, 4.35861363e-01, 4.36455322e-01, 4.17315805e-01,\n",
       "        3.72939553e-01, 3.19532369e-01, 2.62093871e-01, 1.95490090e-01,\n",
       "        1.10068602e-01, 3.33015756e-02, 1.49076522e-02, 4.19693578e-03],\n",
       "       [5.35087129e-04, 6.83628614e-03, 1.78366982e-02, 4.15525258e-02,\n",
       "        9.21697145e-02, 1.75452401e-01, 2.68930946e-01, 3.50138032e-01,\n",
       "        4.05819983e-01, 4.29182936e-01, 4.32008406e-01, 4.25138498e-01,\n",
       "        4.17202331e-01, 4.26517124e-01, 4.46269714e-01, 4.37462178e-01,\n",
       "        4.31383155e-01, 4.39839682e-01, 4.37531315e-01, 4.10582212e-01,\n",
       "        3.64624490e-01, 3.16961584e-01, 2.64687325e-01, 2.03275172e-01,\n",
       "        1.22089384e-01, 3.87405438e-02, 1.32464326e-02, 6.01123855e-03],\n",
       "       [1.88952643e-03, 4.23009336e-03, 1.09840412e-02, 3.50483659e-02,\n",
       "        9.34472137e-02, 1.88539134e-01, 2.83203442e-01, 3.59902029e-01,\n",
       "        4.08999444e-01, 4.29232415e-01, 4.29961736e-01, 4.25459425e-01,\n",
       "        4.24473578e-01, 4.37500989e-01, 4.45868193e-01, 4.29576331e-01,\n",
       "        4.31029977e-01, 4.40872709e-01, 4.35669911e-01, 4.08835828e-01,\n",
       "        3.68682630e-01, 3.23595254e-01, 2.72148416e-01, 2.10103614e-01,\n",
       "        1.29509337e-01, 4.70752602e-02, 1.46472351e-02, 1.29984993e-03],\n",
       "       [6.29667387e-04, 3.78038259e-03, 8.82859872e-03, 3.76112151e-02,\n",
       "        1.00037596e-01, 2.03870060e-01, 2.94848027e-01, 3.62338101e-01,\n",
       "        4.04983627e-01, 4.24219431e-01, 4.25734219e-01, 4.24896560e-01,\n",
       "        4.29690347e-01, 4.41589210e-01, 4.41420830e-01, 4.28847098e-01,\n",
       "        4.36732392e-01, 4.41686762e-01, 4.30818668e-01, 4.08476977e-01,\n",
       "        3.74859539e-01, 3.32399095e-01, 2.78171370e-01, 2.10234130e-01,\n",
       "        1.30739811e-01, 5.58149117e-02, 2.00265365e-02, 4.65868176e-03],\n",
       "       [6.68858912e-04, 2.42232634e-03, 1.34554056e-02, 4.05314591e-02,\n",
       "        1.11517158e-01, 2.17277707e-01, 3.01960429e-01, 3.58752508e-01,\n",
       "        3.94615342e-01, 4.12411295e-01, 4.16600524e-01, 4.20853932e-01,\n",
       "        4.31522513e-01, 4.42882874e-01, 4.41693965e-01, 4.36484084e-01,\n",
       "        4.39654822e-01, 4.36308002e-01, 4.25664953e-01, 4.07981885e-01,\n",
       "        3.79489213e-01, 3.34604592e-01, 2.76264729e-01, 2.04905061e-01,\n",
       "        1.28059702e-01, 6.08676452e-02, 2.23867666e-02, 4.81638637e-03],\n",
       "       [0.00000000e+00, 3.33987103e-03, 1.80231601e-02, 5.10302418e-02,\n",
       "        1.30724653e-01, 2.30837753e-01, 3.05749294e-01, 3.53067995e-01,\n",
       "        3.82378841e-01, 3.98060788e-01, 4.05184628e-01, 4.13915781e-01,\n",
       "        4.25882585e-01, 4.34873603e-01, 4.39198188e-01, 4.38513790e-01,\n",
       "        4.35716182e-01, 4.30801014e-01, 4.24577591e-01, 4.09247925e-01,\n",
       "        3.79330832e-01, 3.29833114e-01, 2.65712685e-01, 1.93191986e-01,\n",
       "        1.20927218e-01, 6.30425227e-02, 2.34702159e-02, 3.39374872e-03],\n",
       "       [1.31769838e-03, 3.42826546e-03, 2.14088402e-02, 6.59627892e-02,\n",
       "        1.49318661e-01, 2.43267300e-01, 3.11992128e-01, 3.53853207e-01,\n",
       "        3.77760733e-01, 3.92984363e-01, 4.03537369e-01, 4.11538907e-01,\n",
       "        4.17680037e-01, 4.28482066e-01, 4.36643311e-01, 4.35197994e-01,\n",
       "        4.32485086e-01, 4.32179884e-01, 4.27637693e-01, 4.10360413e-01,\n",
       "        3.73536847e-01, 3.19322588e-01, 2.53346378e-01, 1.81086610e-01,\n",
       "        1.13831609e-01, 5.94284484e-02, 1.86088019e-02, 5.11269754e-03],\n",
       "       [2.50822092e-04, 4.11524220e-03, 2.82593266e-02, 7.75023693e-02,\n",
       "        1.60422981e-01, 2.51150497e-01, 3.19443455e-01, 3.62055235e-01,\n",
       "        3.87153001e-01, 4.03448124e-01, 4.13806707e-01, 4.20629076e-01,\n",
       "        4.26083069e-01, 4.32964793e-01, 4.37470417e-01, 4.35514129e-01,\n",
       "        4.33926298e-01, 4.35502168e-01, 4.27474265e-01, 4.02004560e-01,\n",
       "        3.58848046e-01, 3.00114888e-01, 2.31868793e-01, 1.61921630e-01,\n",
       "        1.00770386e-01, 5.32995119e-02, 1.85106451e-02, 3.48736867e-03],\n",
       "       [0.00000000e+00, 6.04626633e-03, 3.00944580e-02, 8.11276543e-02,\n",
       "        1.58530923e-01, 2.44457240e-01, 3.18518672e-01, 3.69902517e-01,\n",
       "        4.01035920e-01, 4.18619488e-01, 4.27890550e-01, 4.32832020e-01,\n",
       "        4.35974401e-01, 4.37790093e-01, 4.37178193e-01, 4.36291827e-01,\n",
       "        4.36213239e-01, 4.33510606e-01, 4.18103355e-01, 3.83467960e-01,\n",
       "        3.29227733e-01, 2.65103348e-01, 1.97921838e-01, 1.36246025e-01,\n",
       "        8.60188492e-02, 4.36518425e-02, 1.59303305e-02, 1.19425822e-03],\n",
       "       [5.35087129e-04, 5.19688738e-03, 2.82161700e-02, 7.19446474e-02,\n",
       "        1.37626897e-01, 2.19789460e-01, 3.00004471e-01, 3.63102576e-01,\n",
       "        4.04176877e-01, 4.26536604e-01, 4.35839648e-01, 4.37228323e-01,\n",
       "        4.36014983e-01, 4.33062208e-01, 4.33908292e-01, 4.35426901e-01,\n",
       "        4.33944870e-01, 4.22191255e-01, 3.91977233e-01, 3.42579412e-01,\n",
       "        2.81265033e-01, 2.15688665e-01, 1.57054448e-01, 1.08026374e-01,\n",
       "        6.84241591e-02, 3.39121816e-02, 1.13351741e-02, 6.52137439e-04],\n",
       "       [5.18365657e-04, 6.70730345e-04, 2.22486480e-02, 5.43229509e-02,\n",
       "        1.05145999e-01, 1.74265984e-01, 2.53693383e-01, 3.26426089e-01,\n",
       "        3.83172151e-01, 4.19439249e-01, 4.37272247e-01, 4.42748658e-01,\n",
       "        4.41229117e-01, 4.39709515e-01, 4.40172295e-01, 4.36958053e-01,\n",
       "        4.21393209e-01, 3.90156673e-01, 3.40726665e-01, 2.81086246e-01,\n",
       "        2.19605768e-01, 1.63105377e-01, 1.16420395e-01, 7.87865575e-02,\n",
       "        4.65888376e-02, 2.00178782e-02, 5.98441810e-03, 1.20394604e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.12796956e-02, 3.15063914e-02,\n",
       "        6.83109962e-02, 1.17077153e-01, 1.81261225e-01, 2.53276457e-01,\n",
       "        3.21397805e-01, 3.74500619e-01, 4.09515421e-01, 4.27721228e-01,\n",
       "        4.33255370e-01, 4.31891142e-01, 4.23331313e-01, 4.04487162e-01,\n",
       "        3.69818036e-01, 3.21640492e-01, 2.64575229e-01, 2.08024629e-01,\n",
       "        1.58184093e-01, 1.14172830e-01, 7.99376741e-02, 5.16928108e-02,\n",
       "        2.75634872e-02, 1.18249114e-02, 3.78651388e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 6.26906774e-03, 1.69801637e-02,\n",
       "        3.76677865e-02, 6.63204411e-02, 1.07847225e-01, 1.60323452e-01,\n",
       "        2.16876833e-01, 2.72759651e-01, 3.17106450e-01, 3.44748183e-01,\n",
       "        3.55685563e-01, 3.54588204e-01, 3.38447522e-01, 3.08901464e-01,\n",
       "        2.72985121e-01, 2.31570800e-01, 1.86569298e-01, 1.46221319e-01,\n",
       "        1.08092530e-01, 7.77642125e-02, 5.29337334e-02, 3.31040237e-02,\n",
       "        1.57435705e-02, 7.95075691e-03, 1.66611129e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 9.62886760e-04, 6.64335444e-03,\n",
       "        1.84301341e-02, 3.64745676e-02, 6.39644608e-02, 9.72421965e-02,\n",
       "        1.37468857e-01, 1.73342283e-01, 2.03804118e-01, 2.20486682e-01,\n",
       "        2.28990212e-01, 2.27925197e-01, 2.14591436e-01, 1.96415644e-01,\n",
       "        1.76667408e-01, 1.51801073e-01, 1.24980847e-01, 9.74695372e-02,\n",
       "        7.08538942e-02, 5.00746402e-02, 3.21885894e-02, 1.98127971e-02,\n",
       "        8.11774827e-03, 2.57410757e-03, 1.73903317e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.35415966e-04,\n",
       "        9.44979695e-03, 2.03033435e-02, 3.91743498e-02, 5.82303972e-02,\n",
       "        8.38450284e-02, 1.02308716e-01, 1.19060968e-01, 1.31449375e-01,\n",
       "        1.36467827e-01, 1.34815826e-01, 1.28209095e-01, 1.14195358e-01,\n",
       "        1.02482627e-01, 8.66325877e-02, 7.04246735e-02, 5.47600938e-02,\n",
       "        4.08959698e-02, 2.63415114e-02, 1.43104250e-02, 4.88353785e-03,\n",
       "        4.70880042e-04, 9.86566895e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.79206987e-03, 6.91856574e-03, 9.89855776e-03, 1.59323240e-02,\n",
       "        1.88054679e-02, 2.25677793e-02, 2.79023292e-02, 3.34793669e-02,\n",
       "        3.83831733e-02, 3.94436802e-02, 4.47654139e-02, 4.11269755e-02,\n",
       "        3.48246750e-02, 2.88777823e-02, 2.29550659e-02, 1.50825861e-02,\n",
       "        1.15637536e-02, 6.90881731e-03, 6.87407352e-03, 1.41963918e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it would be good to use a Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2445 - accuracy: 0.9299 - val_loss: 0.1301 - val_accuracy: 0.9644\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1031 - accuracy: 0.9695 - val_loss: 0.1213 - val_accuracy: 0.9684\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0739 - accuracy: 0.9769 - val_loss: 0.1127 - val_accuracy: 0.9708\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 0.1328 - val_accuracy: 0.9724\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0475 - accuracy: 0.9857 - val_loss: 0.1286 - val_accuracy: 0.9754\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.1576 - val_accuracy: 0.9714\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0398 - accuracy: 0.9886 - val_loss: 0.1344 - val_accuracy: 0.9772\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.1707 - val_accuracy: 0.9750\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 0.2017 - val_accuracy: 0.9722\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.1956 - val_accuracy: 0.9762\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0322 - accuracy: 0.9921 - val_loss: 0.1522 - val_accuracy: 0.9790\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.1785 - val_accuracy: 0.9786\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0313 - accuracy: 0.9932 - val_loss: 0.2371 - val_accuracy: 0.9734\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 0.2752 - val_accuracy: 0.9714\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0274 - accuracy: 0.9939 - val_loss: 0.2660 - val_accuracy: 0.9722\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 0.2639 - val_accuracy: 0.9748\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0255 - accuracy: 0.9944 - val_loss: 0.2901 - val_accuracy: 0.9766\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0269 - accuracy: 0.9948 - val_loss: 0.3041 - val_accuracy: 0.9740\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0324 - accuracy: 0.9948 - val_loss: 0.2738 - val_accuracy: 0.9780\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0265 - accuracy: 0.9950 - val_loss: 0.3115 - val_accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(axis=(1, 2))\n",
    "model = tf.keras.Sequential()\n",
    "model.add(norm_layer)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"softplus\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"softplus\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])\n",
    "norm_layer.adapt(X_train)  # must be called before model.fit()\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try without the Normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3073 - accuracy: 0.9068 - val_loss: 0.1250 - val_accuracy: 0.9650\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1304 - accuracy: 0.9601 - val_loss: 0.1095 - val_accuracy: 0.9662\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0862 - accuracy: 0.9729 - val_loss: 0.0806 - val_accuracy: 0.9748\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.0615 - accuracy: 0.9804 - val_loss: 0.0877 - val_accuracy: 0.9736\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.0780 - val_accuracy: 0.9796\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.0830 - val_accuracy: 0.9806\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.0856 - val_accuracy: 0.9784\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.0888 - val_accuracy: 0.9794\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0852 - val_accuracy: 0.9840\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.0946 - val_accuracy: 0.9804\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0994 - val_accuracy: 0.9804\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0948 - val_accuracy: 0.9832\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1009 - val_accuracy: 0.9810\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1078 - val_accuracy: 0.9840\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1446 - val_accuracy: 0.9748\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1109 - val_accuracy: 0.9818\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.1135 - val_accuracy: 0.9816\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1652 - val_accuracy: 0.9794\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1572 - val_accuracy: 0.9802\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1255 - val_accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Input(shape=[28, 28]))  # without the batch size - only the shape of the instances\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(300, activation=\"softplus\"))\n",
    "model2.add(tf.keras.layers.Dense(100, activation=\"softplus\"))\n",
    "model2.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer2 = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer2, \n",
    "              metrics=[\"accuracy\"])\n",
    "history2 = model2.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems  we get better performance without the Normalization layer in this case.\n",
    "\n",
    "Now let's try to tune the learning rate using the LearningRateScheduler callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    max = 10\n",
    "    min = 1e-5\n",
    "    n_epochs = 30\n",
    "    factor = (max / min) ** (1 / n_epochs)\n",
    "    return lr * factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 1.5848931524233436e-05.\n",
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 1.5155 - accuracy: 0.6374 - val_loss: 0.7276 - val_accuracy: 0.8688 - lr: 1.5849e-05\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 2.5118862961658603e-05.\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.5457 - accuracy: 0.8643 - val_loss: 0.3409 - val_accuracy: 0.9158 - lr: 2.5119e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 3.9810715050325415e-05.\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3723 - accuracy: 0.8959 - val_loss: 0.2674 - val_accuracy: 0.9272 - lr: 3.9811e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 6.309573111472314e-05.\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3187 - accuracy: 0.9088 - val_loss: 0.2332 - val_accuracy: 0.9342 - lr: 6.3096e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 9.999999180006416e-05.\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2878 - accuracy: 0.9171 - val_loss: 0.2129 - val_accuracy: 0.9396 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.00015848930371071868.\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2588 - accuracy: 0.9245 - val_loss: 0.1971 - val_accuracy: 0.9426 - lr: 1.5849e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.00025118861808497037.\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2204 - accuracy: 0.9358 - val_loss: 0.1487 - val_accuracy: 0.9604 - lr: 2.5119e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0003981071216742149.\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1744 - accuracy: 0.9483 - val_loss: 0.1318 - val_accuracy: 0.9626 - lr: 3.9811e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0006309572880840001.\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1372 - accuracy: 0.9575 - val_loss: 0.1333 - val_accuracy: 0.9602 - lr: 6.3096e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.000999999941063873.\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1056 - accuracy: 0.9676 - val_loss: 0.1124 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0015848930832336496.\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0893 - accuracy: 0.9715 - val_loss: 0.0882 - val_accuracy: 0.9746 - lr: 0.0016\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.002511886273102629.\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0809 - accuracy: 0.9751 - val_loss: 0.0792 - val_accuracy: 0.9782 - lr: 0.0025\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003981071308995074.\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0869 - accuracy: 0.9733 - val_loss: 0.0832 - val_accuracy: 0.9746 - lr: 0.0040\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0063095731575987775.\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1345 - accuracy: 0.9632 - val_loss: 0.1214 - val_accuracy: 0.9688 - lr: 0.0063\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.00999999941063873.\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1986 - accuracy: 0.9517 - val_loss: 0.2067 - val_accuracy: 0.9582 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0158489315703599.\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2728 - accuracy: 0.9391 - val_loss: 0.2033 - val_accuracy: 0.9506 - lr: 0.0158\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.02511886273102629.\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6165 - accuracy: 0.8691 - val_loss: 0.4259 - val_accuracy: 0.9154 - lr: 0.0251\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.03981071530402096.\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.9985 - accuracy: 0.2627 - val_loss: 2.0909 - val_accuracy: 0.1882 - lr: 0.0398\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0630957345280814.\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.2511 - accuracy: 0.1365 - val_loss: 2.3052 - val_accuracy: 0.1126 - lr: 0.0631\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.09999999853452772.\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.3665 - accuracy: 0.1063 - val_loss: 2.2983 - val_accuracy: 0.1212 - lr: 0.1000\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.15848932160778623.\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.3327 - accuracy: 0.1030 - val_loss: 2.3146 - val_accuracy: 0.0998 - lr: 0.1585\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.25118863911863737.\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.3323 - accuracy: 0.1001 - val_loss: 2.3408 - val_accuracy: 0.1018 - lr: 0.2512\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.3981071589443968.\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.3482 - accuracy: 0.1002 - val_loss: 2.3120 - val_accuracy: 0.0986 - lr: 0.3981\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.6309573452808139.\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.3744 - accuracy: 0.1004 - val_loss: 2.3627 - val_accuracy: 0.0916 - lr: 0.6310\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 1.0000000325787752.\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.4117 - accuracy: 0.0984 - val_loss: 2.4081 - val_accuracy: 0.1060 - lr: 1.0000\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 1.5848931924611134.\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.4699 - accuracy: 0.1003 - val_loss: 2.4490 - val_accuracy: 0.0964 - lr: 1.5849\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 2.5118864856533696.\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.5650 - accuracy: 0.0975 - val_loss: 2.5198 - val_accuracy: 0.0978 - lr: 2.5119\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 3.981071967311951.\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.7009 - accuracy: 0.1015 - val_loss: 2.6698 - val_accuracy: 0.0966 - lr: 3.9811\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 6.309573830676122.\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.8785 - accuracy: 0.1007 - val_loss: 2.6180 - val_accuracy: 0.1060 - lr: 6.3096\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 10.00000032578775.\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4078 - accuracy: 0.1023 - val_loss: 3.0316 - val_accuracy: 0.1060 - lr: 10.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[28, 28]))  # without the batch size - only the shape of the instances\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"softplus\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"softplus\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, 31), history.history['loss'])\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss starts to climb back around Epoch 13. From the training logs we can find out the learning rate on that epoch:\n",
    "```\n",
    "Epoch 13: LearningRateScheduler setting learning rate to 0.003981071308995074.\n",
    "Epoch 13/30\n",
    "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0869 - accuracy: 0.9733 - val_loss: 0.0832 - val_accuracy: 0.9746 - lr: 0.0040\n",
    "```\n",
    "So let's use half of that, `0.002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('my_logs/exercises/run_2024_04_04_12_51_36')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "def get_run_logdir(root_logdir=\"my_logs/exercises/\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.9227INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2489 - accuracy: 0.9227 - val_loss: 0.1024 - val_accuracy: 0.9682\n",
      "Epoch 2/50\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9696INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1009 - accuracy: 0.9695 - val_loss: 0.0955 - val_accuracy: 0.9712\n",
      "Epoch 3/50\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9782INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0688 - accuracy: 0.9782 - val_loss: 0.0728 - val_accuracy: 0.9808\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0485 - accuracy: 0.9846 - val_loss: 0.0898 - val_accuracy: 0.9752\n",
      "Epoch 5/50\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9877INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_exercise_checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0379 - accuracy: 0.9878 - val_loss: 0.0697 - val_accuracy: 0.9820\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.1092 - val_accuracy: 0.9764\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 0.0982 - val_accuracy: 0.9782\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.0990 - val_accuracy: 0.9814\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.1431 - val_accuracy: 0.9730\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.1268 - val_accuracy: 0.9806\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.1282 - val_accuracy: 0.9802\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.1268 - val_accuracy: 0.9810\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.1325 - val_accuracy: 0.9808\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.1207 - val_accuracy: 0.9834\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.1483 - val_accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[28, 28]))  # without the batch size - only the shape of the instances\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"softplus\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"softplus\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimal_learning_rate = 0.002\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.002)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\"my_exercise_checkpoints\", save_best_only=True)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(get_run_logdir())\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=50,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[es_callback, cp_callback, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0770 - accuracy: 0.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07695230096578598, 0.9812999963760376]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray, we get over 98% accuracy! \n",
    "\n",
    "Now let's use keras tuner to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class MyClassificationHyperModel(kt.HyperModel):\n",
    "\n",
    "    def build(self, hp: kt.HyperParameters) -> tf.keras.Model:\n",
    "        n_hidden = hp.Int(\"n_hidden\", min_value=1, max_value=8, default=2)\n",
    "        n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "        optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"Adam\"])\n",
    "        if optimizer == \"sgd\":\n",
    "            optimizer = tf.keras.optimizers.legacy.SGD()\n",
    "        else:\n",
    "            optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        for _ in range(n_hidden):\n",
    "            model.add(tf.keras.layers.Dense(n_neurons, activation=\"softplus\"))\n",
    "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp: kt.HyperParameters, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = tf.keras.layers.Normalization()\n",
    "            norm_layer.adapt(X)\n",
    "            X = norm_layer(X)\n",
    "        return model.fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 02s]\n",
      "val_accuracy: 0.9527999758720398\n",
      "\n",
      "Best val_accuracy So Far: 0.9782000184059143\n",
      "Total elapsed time: 00h 11m 46s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    MyClassificationHyperModel(), objective=\"val_accuracy\", max_trials=5, overwrite=True,\n",
    "    directory=\"exercise_mnist\", project_name=\"my_rnd_search\", seed=42\n",
    ")\n",
    "root_logdir = Path(random_search_tuner.project_dir) / \"tensorboard\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(root_logdir)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid),\n",
    "                           callbacks=[tensorboard_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 2,\n",
       " 'n_neurons': 251,\n",
       " 'learning_rate': 0.001715074355925934,\n",
       " 'optimizer': 'Adam',\n",
       " 'normalize': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = random_search_tuner.get_best_hyperparameters()[0]\n",
    "best_params.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 4.5526 - accuracy: 0.9698\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4304 - accuracy: 0.9696\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3333 - accuracy: 0.9660\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2426 - accuracy: 0.9623\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2331 - accuracy: 0.9632\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2124 - accuracy: 0.9633\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1657 - accuracy: 0.9675\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1523 - accuracy: 0.9705\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1420 - accuracy: 0.9718\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1328 - accuracy: 0.9737\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.9243 - accuracy: 0.3045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9243015050888062, 0.304500013589859]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = random_search_tuner.get_best_models()[0]\n",
    "best_model.fit(X_train_full, y_train_full, epochs=10)\n",
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtf???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handson-ml3-DRIwlIAE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
