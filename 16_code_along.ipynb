{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Shakespearean Text Using a Character RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Training Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaoschachampis/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TensorFlow to use CPU only\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the text with a TextVectorization layer\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
    "                                                   standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0]\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " ' ',\n",
       " 'e',\n",
       " 't',\n",
       " 'o',\n",
       " 'a',\n",
       " 'i',\n",
       " 'h',\n",
       " 's',\n",
       " 'r',\n",
       " 'n',\n",
       " '\\n',\n",
       " 'l',\n",
       " 'd',\n",
       " 'u',\n",
       " 'm',\n",
       " 'y',\n",
       " 'w',\n",
       " ',',\n",
       " 'c',\n",
       " 'f',\n",
       " 'g',\n",
       " 'b',\n",
       " 'p',\n",
       " ':',\n",
       " 'k',\n",
       " 'v',\n",
       " '.',\n",
       " \"'\",\n",
       " ';',\n",
       " '?',\n",
       " '!',\n",
       " '-',\n",
       " 'j',\n",
       " 'q',\n",
       " 'x',\n",
       " 'z',\n",
       " '3',\n",
       " '&',\n",
       " '$']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 is reserved for padding tokens and 1 for unknown characters\n",
    "text_vec_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded -=2  # drop tokens 0 (pad) and 1 (unknown), which we will not use\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct characters\n",
    "dataset_size = len(encoded) # total number of characters - 1,115,394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to prepare the dataset for a Sequence-to-Sequence RNN\n",
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    # increase the length by 1 since we need the next character for the target\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the logic of the function line by line to understand it better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(19, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(encoded)\n",
    "for item in ds.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.window(10, shift=1, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(19, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 10:21:16.446959: W tensorflow/core/framework/dataset.cc:959] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "# ds.window() returns a dataset of windows, i.e. a nested dataset\n",
    "for item in ds.take(1):\n",
    "    for c in item.take(1):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([19  5  8  7  2  0 18  5  2  5], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# That's why we use the flat_map method\n",
    "ds = ds.flat_map(lambda window_ds: window_ds.batch(10))\n",
    "for item in ds.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[19  5  8  7  2  0 18  5  2  5]\n",
      " [ 5  8  7  2  0 18  5  2  5 35]\n",
      " [ 8  7  2  0 18  5  2  5 35  1]\n",
      " [ 7  2  0 18  5  2  5 35  1  9]], shape=(4, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ds = ds.batch(4)\n",
    "for item in ds.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(4, 9), dtype=int64, numpy=\n",
      "array([[19,  5,  8,  7,  2,  0, 18,  5,  2],\n",
      "       [ 5,  8,  7,  2,  0, 18,  5,  2,  5],\n",
      "       [ 8,  7,  2,  0, 18,  5,  2,  5, 35],\n",
      "       [ 7,  2,  0, 18,  5,  2,  5, 35,  1]])>, <tf.Tensor: shape=(4, 9), dtype=int64, numpy=\n",
      "array([[ 5,  8,  7,  2,  0, 18,  5,  2,  5],\n",
      "       [ 8,  7,  2,  0, 18,  5,  2,  5, 35],\n",
      "       [ 7,  2,  0, 18,  5,  2,  5, 35,  1],\n",
      "       [ 2,  0, 18,  5,  2,  5, 35,  1,  9]])>)\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
    "for item in ds.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this batch, the first input is `[19,  5,  8,  7,  2,  0, 18,  5,  2]` and the corresponding output is `[ 5,  8,  7,  2,  0, 18,  5,  2,  5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "tf.random.set_seed(42)\n",
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True,\n",
    "                       seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[15  0  9 ... 11 11  0]\n",
      " [25  1  0 ...  3  9  7]\n",
      " [13  7 23 ... 17  0  4]\n",
      " ...\n",
      " [25  1  0 ...  6  1  0]\n",
      " [11 12  0 ... 21 13  2]\n",
      " [ 1  0  5 ...  5  2  6]], shape=(32, 100), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 0  9  3 ... 11  0  2]\n",
      " [ 1  0  3 ...  9  7  2]\n",
      " [ 7 23 10 ...  0  4  7]\n",
      " ...\n",
      " [ 1  0 21 ...  1  0 18]\n",
      " [12  0 15 ... 13  2  0]\n",
      " [ 0  5  2 ...  2  6  0]], shape=(32, 100), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for input, target in train_set.take(1):\n",
    "    print(input)\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building and Training the Char-RNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    # We train to predict the next character, so we can't just let\n",
    "    # the Dense layer output anything it wants\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          624       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 128)         56064     \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 39)          5031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61719 (241.09 KB)\n",
      "Trainable params: 61719 (241.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you think about it, the targets are integer numbers representing character IDs,\n",
    "# # which can be considered class IDs. So the use of sparse_categorical_crossentropy\n",
    "# # loss makes sense\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "#               metrics=[\"accuracy\"])\n",
    "# model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     \"my_shakespeare_model\", monitor=\"val_accuracy\", save_best_only=True\n",
    "# )\n",
    "# history = model.fit(train_set, validation_data=valid_set, epochs=5,\n",
    "#                     callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shakespeare_model = tf.keras.Sequential([\n",
    "#     text_vec_layer,\n",
    "#     tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
    "#     model\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, training the above model hangs or kills the jupyter kernel on my Mac. So, we will go with the\n",
    "\n",
    "pretrained model made available by Jullien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – downloads a pretrained model\n",
    "url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
    "path = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url, extract=True)\n",
    "model_path = Path(path).with_name(\"shakespeare_model\")\n",
    "shakespeare_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 228ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the next character in a sentence\n",
    "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
    "y_pred = tf.argmax(y_proba)  # choose the most probable character\n",
    "text_vec_layer.get_vocabulary()[y_pred + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[2.40598023e-02, 8.39524642e-02, 2.56986148e-03, 6.81132674e-01,\n",
       "         5.57369692e-03, 1.28980115e-01, 3.45016830e-02, 3.45355220e-04,\n",
       "         2.05263589e-03, 1.39599069e-06, 2.25605490e-03, 1.98339135e-03,\n",
       "         1.65986719e-07, 5.30304445e-04, 5.72810995e-06, 2.27981023e-02,\n",
       "         1.22251199e-03, 2.89343833e-03, 2.08538680e-04, 5.40604669e-05,\n",
       "         1.53302904e-06, 3.27079724e-05, 1.37306401e-04, 1.58490217e-03,\n",
       "         3.71308772e-07, 2.42348968e-08, 1.97694171e-03, 2.71507044e-04,\n",
       "         1.92895808e-04, 4.48364037e-04, 1.67209073e-04, 6.41081497e-05,\n",
       "         5.02575084e-08, 4.98080066e-09, 4.04996481e-09, 7.58086642e-08,\n",
       "         1.15317922e-09, 6.51099503e-18, 2.61223176e-09],\n",
       "        [3.84590983e-01, 1.80969892e-06, 6.02273317e-03, 4.99450229e-03,\n",
       "         1.43065963e-05, 5.44819981e-03, 3.13025108e-03, 7.48898042e-03,\n",
       "         1.60934106e-02, 2.84634650e-01, 1.17216809e-02, 1.89255908e-01,\n",
       "         2.26248503e-05, 9.31028393e-04, 7.63864140e-04, 1.89840023e-07,\n",
       "         2.35868376e-02, 3.79373692e-03, 2.93549761e-04, 2.50894111e-04,\n",
       "         4.30203479e-04, 8.73744767e-03, 3.75150405e-02, 1.72283396e-03,\n",
       "         4.00717044e-03, 7.87532481e-05, 1.46196596e-03, 7.40816293e-04,\n",
       "         3.01664986e-04, 6.07117428e-04, 6.00675776e-05, 1.28506904e-03,\n",
       "         2.55257959e-07, 1.42405611e-07, 1.12745411e-05, 1.81129938e-08,\n",
       "         7.51460699e-11, 1.80510559e-19, 2.73843692e-13],\n",
       "        [2.43701070e-05, 3.05432498e-01, 2.57383683e-03, 1.76317841e-01,\n",
       "         5.02325594e-03, 4.11898131e-03, 4.47690394e-03, 6.14171736e-02,\n",
       "         5.50918339e-04, 8.51500873e-03, 6.25439643e-05, 4.68632206e-03,\n",
       "         5.22523047e-03, 1.75087841e-03, 1.75574362e-01, 7.36115326e-04,\n",
       "         3.15333076e-04, 3.71308561e-05, 9.77624301e-03, 6.59212098e-03,\n",
       "         1.14331674e-02, 1.87506512e-01, 1.41036371e-02, 1.28115626e-05,\n",
       "         6.56818331e-04, 3.55083146e-03, 1.81515479e-05, 1.19318371e-03,\n",
       "         2.58423825e-05, 5.50819823e-06, 1.00079405e-05, 1.26891400e-05,\n",
       "         1.36809435e-03, 4.51024011e-04, 6.40729675e-03, 3.73342409e-05,\n",
       "         3.45531670e-09, 4.77300584e-18, 2.25033549e-20],\n",
       "        [3.57631257e-06, 2.82792181e-01, 1.14536484e-10, 4.98398906e-03,\n",
       "         5.02086394e-02, 1.58040412e-03, 3.67154484e-12, 5.37918277e-06,\n",
       "         6.40815616e-01, 2.35138396e-05, 1.30036923e-07, 2.97465152e-03,\n",
       "         8.55426734e-08, 1.65928863e-02, 2.11963169e-07, 1.73029512e-05,\n",
       "         6.80268641e-08, 3.34526533e-07, 1.09911510e-10, 3.89546244e-07,\n",
       "         9.74293354e-11, 3.08000878e-08, 4.90320784e-10, 8.59997051e-09,\n",
       "         2.31054600e-15, 5.10960545e-11, 1.28215532e-07, 7.39996011e-08,\n",
       "         9.75110481e-09, 1.54812909e-08, 6.15759754e-09, 1.90442478e-07,\n",
       "         6.33756088e-08, 1.12757208e-08, 2.37537048e-08, 5.51852512e-18,\n",
       "         1.78862964e-21, 2.44836618e-31, 2.57609973e-20],\n",
       "        [3.88495461e-03, 7.52248839e-02, 1.45951402e-03, 1.30224998e-06,\n",
       "         2.85966713e-02, 1.37501229e-02, 1.14177214e-03, 1.72136053e-02,\n",
       "         2.73246062e-03, 5.11270657e-04, 3.30638606e-04, 3.11833527e-03,\n",
       "         8.40126812e-01, 4.84892894e-07, 1.94299128e-06, 2.47207092e-04,\n",
       "         1.23889913e-04, 9.28845198e-04, 7.41205527e-04, 7.66966332e-06,\n",
       "         8.80138297e-03, 8.25594834e-05, 3.58121528e-04, 2.44058392e-05,\n",
       "         7.00962275e-08, 9.69602843e-06, 9.35075514e-05, 2.93502544e-05,\n",
       "         1.21568301e-04, 1.15605151e-04, 1.97190500e-04, 1.23787743e-06,\n",
       "         1.10571065e-07, 4.79524488e-07, 2.10596245e-05, 6.44064144e-08,\n",
       "         2.91842121e-18, 4.63062412e-22, 8.31380200e-27],\n",
       "        [1.53451572e-06, 9.62339714e-03, 2.41526552e-02, 5.33108115e-01,\n",
       "         2.43843630e-01, 2.22904515e-02, 9.92577150e-03, 2.66747922e-03,\n",
       "         7.14970753e-04, 4.79214415e-02, 2.81396606e-05, 2.88135663e-04,\n",
       "         1.11127589e-02, 1.85945784e-04, 1.13161234e-02, 6.00163359e-03,\n",
       "         5.01026458e-04, 8.24111680e-07, 6.06061192e-03, 2.53899023e-03,\n",
       "         4.92912456e-02, 1.05492892e-02, 2.69971788e-04, 2.54655356e-06,\n",
       "         4.07692278e-04, 5.96167380e-03, 8.43953501e-07, 7.02732825e-04,\n",
       "         5.82873781e-07, 4.21199388e-07, 1.82549428e-07, 7.32704791e-07,\n",
       "         2.74871883e-04, 2.40230220e-04, 1.31110537e-05, 1.72054811e-07,\n",
       "         1.17481372e-10, 3.11943477e-20, 8.50185152e-20],\n",
       "        [7.58359022e-03, 3.12207820e-04, 7.23650381e-02, 6.55766416e-05,\n",
       "         1.09393233e-02, 2.84369220e-04, 1.28879469e-06, 2.82017160e-02,\n",
       "         2.42959987e-03, 2.74986982e-01, 4.19460796e-03, 7.60961771e-02,\n",
       "         1.60364585e-03, 1.34772924e-03, 3.68605215e-05, 3.40206170e-04,\n",
       "         3.35101434e-03, 2.51111155e-03, 3.13761039e-03, 4.75031406e-01,\n",
       "         7.28027817e-06, 6.79378165e-03, 3.36388405e-03, 1.07446387e-04,\n",
       "         3.74672982e-06, 5.18903369e-03, 8.77487764e-04, 1.79806463e-02,\n",
       "         2.00740596e-05, 2.85308022e-04, 1.36073568e-05, 4.80923569e-04,\n",
       "         1.55150097e-08, 3.01622458e-05, 2.42754395e-05, 2.19431558e-06,\n",
       "         1.65085071e-10, 2.86664164e-23, 1.81889348e-13],\n",
       "        [1.74318463e-01, 7.54030934e-03, 1.81452153e-04, 5.69167957e-09,\n",
       "         2.40198538e-01, 4.52223560e-03, 1.12174945e-07, 1.99408922e-03,\n",
       "         3.16008191e-05, 1.21949026e-02, 6.30344003e-02, 9.16106917e-04,\n",
       "         4.87429947e-01, 1.60006152e-06, 3.68401459e-07, 8.32712772e-07,\n",
       "         1.73155713e-05, 1.94819164e-04, 2.42075976e-03, 8.11766222e-05,\n",
       "         1.19612215e-03, 4.69911938e-05, 1.71910832e-03, 8.08882978e-05,\n",
       "         7.70633778e-05, 6.13951534e-06, 6.11492083e-04, 1.27142353e-04,\n",
       "         1.80608360e-04, 1.32219720e-04, 1.42147546e-05, 7.28387095e-04,\n",
       "         1.78060500e-09, 5.24733309e-07, 8.16828161e-10, 2.96382835e-10,\n",
       "         9.45784283e-17, 8.75115272e-23, 3.03238633e-27],\n",
       "        [5.96129939e-06, 3.84566367e-01, 9.22949053e-03, 1.63765535e-01,\n",
       "         2.06806846e-02, 1.21632935e-02, 3.25354300e-02, 1.14038410e-02,\n",
       "         2.49391887e-03, 9.24085826e-03, 4.38769057e-04, 6.07890869e-03,\n",
       "         6.82438686e-02, 5.83342568e-04, 3.62807736e-02, 5.16274013e-03,\n",
       "         5.67741366e-03, 1.05327763e-05, 4.74753082e-02, 1.03289513e-02,\n",
       "         2.04998981e-02, 7.16386586e-02, 1.17228841e-02, 3.97250442e-05,\n",
       "         3.12551530e-03, 6.44271597e-02, 2.11244478e-05, 9.60900215e-04,\n",
       "         1.44978094e-05, 5.82358962e-06, 4.01740135e-06, 1.58403600e-06,\n",
       "         3.19825107e-04, 4.96583176e-04, 4.68390208e-05, 3.08818737e-04,\n",
       "         9.81222499e-08, 7.05997557e-14, 5.39735052e-17],\n",
       "        [1.61238416e-12, 5.94709635e-01, 1.14732425e-10, 3.22095841e-01,\n",
       "         6.55984432e-02, 9.75046866e-03, 9.89777327e-09, 1.05676199e-12,\n",
       "         1.01244268e-06, 6.57096621e-07, 8.90134494e-12, 2.75213843e-08,\n",
       "         2.08230659e-08, 7.57046882e-03, 4.43591652e-08, 5.25920711e-08,\n",
       "         1.57586522e-09, 4.59919646e-13, 2.69717202e-05, 1.13851037e-07,\n",
       "         1.62328874e-07, 2.96348563e-08, 1.01729780e-09, 4.74856564e-14,\n",
       "         2.29091732e-08, 1.95953326e-04, 1.62647456e-13, 4.88776311e-11,\n",
       "         4.49058075e-14, 7.01104824e-14, 2.61642142e-14, 7.51980536e-14,\n",
       "         3.68991877e-08, 4.98703339e-05, 1.93461688e-07, 2.91870261e-13,\n",
       "         2.54952140e-18, 1.25537673e-19, 4.62912602e-25],\n",
       "        [1.13435442e-06, 7.67921656e-02, 5.46629429e-01, 3.62449326e-02,\n",
       "         1.13129020e-02, 2.65944391e-01, 8.23506738e-08, 2.13684762e-05,\n",
       "         3.10718012e-03, 4.53175567e-02, 5.42162570e-06, 4.79989149e-06,\n",
       "         2.69610318e-04, 1.04068425e-02, 1.40289249e-05, 1.27200864e-03,\n",
       "         2.43438499e-05, 3.62790445e-07, 5.35907311e-05, 6.22884036e-05,\n",
       "         1.38950427e-05, 1.45082490e-03, 3.26193665e-04, 5.48500066e-06,\n",
       "         1.76106667e-07, 3.39610124e-04, 1.57670161e-06, 8.38074925e-07,\n",
       "         5.45356158e-07, 3.88452690e-07, 4.66459582e-08, 1.36933815e-08,\n",
       "         3.57980054e-04, 7.93791628e-08, 1.78613027e-05, 8.09519562e-08,\n",
       "         7.70370601e-10, 1.58565071e-16, 5.13954063e-22],\n",
       "        [3.82182130e-04, 9.92463946e-01, 8.98987491e-06, 5.59620443e-04,\n",
       "         1.11224676e-06, 5.27029717e-03, 4.27452760e-04, 2.33700121e-05,\n",
       "         1.05832248e-06, 2.50588091e-05, 6.94631715e-04, 6.72897113e-06,\n",
       "         3.07918327e-07, 3.89990828e-06, 4.30926272e-09, 4.33083733e-06,\n",
       "         5.83487925e-10, 1.27323774e-05, 8.43477835e-07, 1.78505772e-07,\n",
       "         1.91903897e-08, 2.11756368e-09, 2.76321827e-10, 4.35951479e-05,\n",
       "         7.22680180e-11, 2.72558122e-11, 5.48695098e-05, 5.94907164e-08,\n",
       "         6.72378837e-06, 3.63495110e-06, 5.52438166e-07, 3.34870901e-06,\n",
       "         4.53959271e-13, 2.71949158e-10, 3.81920842e-07, 1.12101439e-09,\n",
       "         4.03928598e-16, 6.43064115e-19, 9.35089685e-25],\n",
       "        [5.03248110e-08, 1.29262898e-02, 1.81119516e-03, 8.72588336e-01,\n",
       "         2.58942917e-02, 2.60645878e-02, 5.18289953e-03, 1.44188607e-03,\n",
       "         4.96551977e-04, 6.49486063e-03, 2.54449361e-07, 2.25759606e-04,\n",
       "         4.53858636e-03, 1.49245869e-04, 9.80215380e-04, 8.46763700e-03,\n",
       "         7.51166721e-04, 3.85122121e-08, 4.26872168e-03, 1.31076726e-03,\n",
       "         1.98159157e-03, 1.21511705e-02, 4.46978607e-04, 4.34167049e-07,\n",
       "         3.19306302e-04, 9.11879819e-03, 7.31286534e-08, 6.48202622e-05,\n",
       "         4.07009075e-08, 7.55368390e-08, 3.78246341e-08, 1.84774024e-07,\n",
       "         1.11655600e-05, 2.30914936e-03, 8.13091788e-07, 2.03600348e-06,\n",
       "         1.15645095e-14, 9.60826267e-14, 4.79508122e-19],\n",
       "        [4.82095718e-11, 7.64442205e-01, 1.29352407e-09, 4.23038565e-02,\n",
       "         3.06605548e-02, 1.47052392e-01, 1.54198438e-04, 1.22514421e-09,\n",
       "         1.36895326e-03, 7.17493898e-10, 1.18634283e-10, 2.61289460e-06,\n",
       "         2.59763372e-14, 1.65789539e-03, 3.93048660e-09, 1.23393591e-02,\n",
       "         1.77542497e-05, 1.55331192e-10, 2.82233366e-08, 1.11287662e-07,\n",
       "         1.23480835e-11, 1.06273085e-07, 7.95133470e-09, 1.06058435e-11,\n",
       "         4.19503408e-12, 4.67195022e-13, 7.24873217e-11, 8.14824389e-11,\n",
       "         3.85092392e-12, 5.18265639e-12, 1.40127502e-11, 6.09388581e-12,\n",
       "         3.61286391e-12, 8.98138341e-10, 5.63889421e-11, 7.38527121e-12,\n",
       "         7.02879730e-14, 4.21339386e-25, 1.25205223e-15],\n",
       "        [3.70259255e-01, 3.34306766e-04, 4.00159945e-04, 3.23286019e-02,\n",
       "         1.35904981e-03, 1.23420255e-02, 6.47935231e-05, 5.46062328e-02,\n",
       "         1.79826710e-02, 1.41627803e-01, 3.27223875e-02, 4.84956764e-02,\n",
       "         1.05196364e-01, 1.50045333e-03, 1.16151001e-03, 2.97016493e-04,\n",
       "         9.67745960e-04, 1.14602328e-03, 1.16970201e-04, 5.92756624e-06,\n",
       "         1.00431731e-02, 3.25949775e-04, 6.08543912e-03, 2.16399319e-03,\n",
       "         4.53784782e-03, 1.67690741e-05, 3.01741902e-03, 3.25402035e-03,\n",
       "         1.53348781e-03, 2.41668290e-03, 1.45678132e-04, 3.47158243e-03,\n",
       "         1.24554367e-06, 2.25209556e-06, 1.40069261e-01, 2.20864891e-07,\n",
       "         1.86257176e-09, 2.69748396e-28, 4.96822411e-16],\n",
       "        [1.65028086e-05, 3.84377576e-02, 5.07638324e-03, 3.60932678e-01,\n",
       "         3.13790003e-03, 1.54477009e-03, 3.37427319e-03, 7.14700529e-03,\n",
       "         3.26754735e-03, 5.91745228e-03, 2.57962791e-04, 1.51663914e-03,\n",
       "         2.46583438e-03, 8.65645852e-05, 2.00959132e-03, 2.18206464e-04,\n",
       "         2.15533946e-04, 4.30036416e-05, 1.52701102e-02, 1.11669407e-03,\n",
       "         1.52670899e-02, 5.22003293e-01, 4.03832365e-03, 3.30568255e-05,\n",
       "         2.29317113e-04, 7.81401352e-04, 4.16825460e-05, 1.91508705e-04,\n",
       "         3.73063485e-05, 1.19073702e-05, 3.28419846e-05, 9.28939335e-06,\n",
       "         2.14812128e-04, 4.95468080e-03, 9.96133676e-05, 1.31292029e-06,\n",
       "         2.37818412e-07, 1.13558145e-21, 2.09118644e-16],\n",
       "        [3.05412478e-08, 9.65336800e-01, 1.71189937e-11, 7.88753096e-05,\n",
       "         2.47108750e-02, 3.44195147e-03, 8.22321134e-14, 9.73639587e-08,\n",
       "         3.60479252e-03, 1.57292504e-06, 1.28934081e-08, 7.31718494e-04,\n",
       "         2.72625544e-09, 2.08876841e-03, 4.31850972e-10, 4.39151881e-06,\n",
       "         5.20103627e-10, 1.92214582e-08, 2.71954985e-13, 2.91583224e-09,\n",
       "         1.08017817e-14, 2.09467865e-09, 1.60876437e-10, 5.08344256e-10,\n",
       "         8.78968323e-18, 4.35645145e-13, 5.84806381e-09, 2.18544094e-09,\n",
       "         5.01746755e-10, 8.17705736e-10, 8.28167146e-10, 2.22365792e-09,\n",
       "         7.90109211e-12, 2.29439204e-10, 1.19973295e-10, 3.66691151e-17,\n",
       "         1.86433888e-21, 3.54061286e-33, 5.32923485e-20]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = shakespeare_model.predict([\"To be or not to b\"])\n",
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17, 39)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the model's output is (batch, time_steps, class_probabilities).\n",
    "\n",
    "So we take output[0,-1] which means the first batch (or the first item in the batch - I'm not sure) and the last time step (since we only care about the next character).\n",
    "\n",
    "The result is the 39 class probabilities (probabilities for each character in the vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Fake Shakespearean Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 1, 0, 2, 1, 0, 0, 1]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example use of tf.random.categorical() function\n",
    "log_probas = tf.math.log([[0.5, 0.4, 0.1]])  # probas = 50%, 40%, 10%\n",
    "tf.random.set_seed(42)\n",
    "tf.random.categorical(log_probas, num_samples=8)  # draw 8 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function that uses the supplied temperature\n",
    "def next_char(text, temperature=1):\n",
    "    y_proba = shakespeare_model.predict([text])[0, -1:]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
    "    return text_vec_layer.get_vocabulary()[char_id + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "To be or not to be the duke\n",
      "as it is a proper strange death,\n",
      "and the\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    tf.random.set_seed(42)\n",
    "    print(extend_text(\"To be or not to be\", temperature=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "To be or not to behold?\n",
      "\n",
      "second push:\n",
      "gremio, lord all, a sistermen,\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    print(extend_text(\"To be or not to be\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "To be or not to bef ,mt'&o3fpadm!$\n",
      "wh!nse?bws3est--vgerdjw?c-y-ewznq\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    print(extend_text(\"To be or not to be\", temperature=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stateful RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to prepare sequential, non-overlapping sequences with\n",
    "# batch size of 1 so each batch continues where the previous batch left off.\n",
    "# This technique is appropriate for stateful RNNs.\n",
    "def to_dataset_for_stateful_rnn(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    # shift=length because we can't use overlapping windows\n",
    "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
    "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000],\n",
    "                                                 length)\n",
    "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 0:\n",
      "tf.Tensor(\n",
      "[[19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1\n",
      "   0 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1\n",
      "   4  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24\n",
      "  17  0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23\n",
      "  10 15  3 13]], shape=(1, 100), dtype=int64)\n",
      "target 0:\n",
      "tf.Tensor(\n",
      "[[ 5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0\n",
      "  22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4\n",
      "   8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17\n",
      "   0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10\n",
      "  15  3 13  0]], shape=(1, 100), dtype=int64)\n",
      "Input 1:\n",
      "tf.Tensor(\n",
      "[[ 0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8\n",
      "   0  2  3  0 12  5  1  0  2  6  4  9  0  2  3  0 19  4 14  5  7  6 29 10\n",
      "  10  4 11 11 23 10  8  1  7  3 11 25  1 12 26  0  8  1  7  3 11 25  1 12\n",
      "  26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 19  5  8  7  2 17\n",
      "   0 15  3 13]], shape=(1, 100), dtype=int64)\n",
      "target 1:\n",
      "tf.Tensor(\n",
      "[[ 4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8  0\n",
      "   2  3  0 12  5  1  0  2  6  4  9  0  2  3  0 19  4 14  5  7  6 29 10 10\n",
      "   4 11 11 23 10  8  1  7  3 11 25  1 12 26  0  8  1  7  3 11 25  1 12 26\n",
      "  10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 19  5  8  7  2 17  0\n",
      "  15  3 13  0]], shape=(1, 100), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i, (input, target) in enumerate(stateful_train_set.take(2)):\n",
    "    print(f\"Input {i}:\")\n",
    "    print(input)\n",
    "    print(f\"target {i}:\")\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    # batch input shape has all the dimensions except the last one (n_features)\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16,\n",
    "                              batch_input_shape=[1, None]),\n",
    "    # stateful=True to preserve the state between training iterations\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True) ,\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the states at the end of each epoch\n",
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – use a different directory to save the checkpoints\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_stateful_shakespeare_model\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   9997/Unknown - 165s 16ms/step - loss: 1.8691 - accuracy: 0.4499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 18:44:46.889270: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12238912183930890742\n",
      "2024-05-22 18:44:46.889285: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16135087444076161340\n",
      "2024-05-22 18:44:46.889288: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5515724840522351501\n",
      "2024-05-22 18:44:46.889307: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10482379356136224177\n",
      "2024-05-22 18:44:46.889312: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10453229208265020866\n",
      "2024-05-22 18:44:46.889326: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18347746450447521286\n",
      "2024-05-22 18:44:46.889333: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15616489207521605139\n",
      "2024-05-22 18:44:46.889344: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18060592171152894285\n",
      "2024-05-22 18:44:46.889349: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4399266981960768085\n",
      "2024-05-22 18:44:46.889354: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1944453487651814313\n",
      "2024-05-22 18:44:46.889361: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13815263755474250949\n",
      "2024-05-22 18:44:46.889371: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6292276460493240917\n",
      "2024-05-22 18:44:46.889375: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11462774895183961989\n",
      "2024-05-22 18:44:50.010823: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15891746165221922025\n",
      "2024-05-22 18:44:50.010837: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6159451349992740575\n",
      "2024-05-22 18:44:50.010840: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 11104161964939687009\n",
      "2024-05-22 18:44:50.010844: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11005812578364983677\n",
      "2024-05-22 18:44:50.010847: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13868283739469109771\n",
      "2024-05-22 18:44:50.010851: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15351114906988432933\n",
      "2024-05-22 18:44:50.010855: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2854151823739392614\n",
      "2024-05-22 18:44:50.010858: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5226008891649984310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 169s 17ms/step - loss: 1.8690 - accuracy: 0.4499 - val_loss: 1.7189 - val_accuracy: 0.4870\n",
      "Epoch 2/10\n",
      "9998/9999 [============================>.] - ETA: 0s - loss: 1.5657 - accuracy: 0.5285INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 162s 16ms/step - loss: 1.5657 - accuracy: 0.5285 - val_loss: 1.6244 - val_accuracy: 0.5142\n",
      "Epoch 3/10\n",
      "9996/9999 [============================>.] - ETA: 0s - loss: 1.4874 - accuracy: 0.5484INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 166s 17ms/step - loss: 1.4874 - accuracy: 0.5484 - val_loss: 1.5826 - val_accuracy: 0.5267\n",
      "Epoch 4/10\n",
      "9997/9999 [============================>.] - ETA: 0s - loss: 1.4481 - accuracy: 0.5585INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 167s 17ms/step - loss: 1.4481 - accuracy: 0.5585 - val_loss: 1.5599 - val_accuracy: 0.5329\n",
      "Epoch 5/10\n",
      "9999/9999 [==============================] - ETA: 0s - loss: 1.4239 - accuracy: 0.5649INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 161s 16ms/step - loss: 1.4239 - accuracy: 0.5649 - val_loss: 1.5482 - val_accuracy: 0.5358\n",
      "Epoch 6/10\n",
      "9997/9999 [============================>.] - ETA: 0s - loss: 1.4072 - accuracy: 0.5693INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 144s 14ms/step - loss: 1.4072 - accuracy: 0.5693 - val_loss: 1.5402 - val_accuracy: 0.5385\n",
      "Epoch 7/10\n",
      "9999/9999 [==============================] - ETA: 0s - loss: 1.3952 - accuracy: 0.5719INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 141s 14ms/step - loss: 1.3952 - accuracy: 0.5719 - val_loss: 1.5325 - val_accuracy: 0.5407\n",
      "Epoch 8/10\n",
      "9999/9999 [==============================] - 137s 14ms/step - loss: 1.3857 - accuracy: 0.5742 - val_loss: 1.5316 - val_accuracy: 0.5397\n",
      "Epoch 9/10\n",
      "9999/9999 [==============================] - ETA: 0s - loss: 1.3783 - accuracy: 0.5759INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 139s 14ms/step - loss: 1.3783 - accuracy: 0.5759 - val_loss: 1.5262 - val_accuracy: 0.5420\n",
      "Epoch 10/10\n",
      "9996/9999 [============================>.] - ETA: 0s - loss: 1.3720 - accuracy: 0.5775INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_stateful_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 165s 16ms/step - loss: 1.3720 - accuracy: 0.5775 - val_loss: 1.5197 - val_accuracy: 0.5443\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(stateful_train_set, validation_data=stateful_valid_set,\n",
    "                    epochs=10, callbacks=[ResetStatesCallback(), model_ckpt])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split the imdb movie reviews dataset\n",
    "raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "tf.random.set_seed(42)\n",
    "train_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\n",
    "valid_set = raw_valid_set.batch(32).prefetch(1)\n",
    "test_set = raw_test_set.batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n",
      "Label: 0\n",
      "I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.\n",
      "Label: 0\n",
      "Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.\n",
      "Label: 0\n",
      "This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.\n",
      "Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 10:22:34.696730: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for review, label in raw_train_set.take(4):\n",
    "    print(review.numpy().decode(\"utf-8\"))\n",
    "    print(\"Label:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text to the word level with TextVectorization layer\n",
    "vocab_size = 1000  # limit max number of tokens\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "704/704 [==============================] - 82s 115ms/step - loss: 0.6934 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5028\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 69s 97ms/step - loss: 0.6928 - accuracy: 0.5018 - val_loss: 0.6937 - val_accuracy: 0.5004\n"
     ]
    }
   ],
   "source": [
    "# Create the model for sentiment analysis and train it\n",
    "embed_size = 128\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_size),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No good performance because of the many padding tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Masking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "\n",
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "704/704 [==============================] - 297s 419ms/step - loss: 0.5058 - accuracy: 0.7511 - val_loss: 0.4340 - val_accuracy: 0.8192\n",
      "Epoch 2/3\n",
      "704/704 [==============================] - 295s 420ms/step - loss: 0.3478 - accuracy: 0.8507 - val_loss: 0.3779 - val_accuracy: 0.8360\n",
      "Epoch 3/3\n",
      "704/704 [==============================] - 283s 402ms/step - loss: 0.2933 - accuracy: 0.8801 - val_loss: 0.3246 - val_accuracy: 0.8632\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# For some reason the accuracy doesn't go up on the  Mac GPU\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embed_size = 128\n",
    "    tf.random.set_seed(42)\n",
    "    model = tf.keras.Sequential([\n",
    "        text_vec_layer,\n",
    "        tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n",
    "        tf.keras.layers.GRU(128),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir())\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "    history = model.fit(train_set, validation_data=valid_set, epochs=3,\n",
    "                        callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the mask manually \n",
    "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "token_ids = text_vec_layer(inputs)\n",
    "mask = tf.math.not_equal(token_ids, 0)\n",
    "Z = tf.keras.layers.Embedding(vocab_size, embed_size)(token_ids)\n",
    "Z = tf.keras.layers.GRU(128, dropout=0.2)(Z, mask=mask)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(Z)\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[86, 18], [11, 7, 1, 116, 217]]>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of masking, use ragged tensors\n",
    "text_vec_layer_ragged = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size, ragged=True\n",
    ")\n",
    "text_vec_layer_ragged.adapt(train_set.map(lambda reviews, labels: reviews))\n",
    "text_vec_layer_ragged([\"Great movie!\", \"This is DiCaprio's best role.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
       "array([[ 86,  18,   0,   0,   0],\n",
       "       [ 11,   7,   1, 116, 217]])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contrast with padded output of text_vec_layer\n",
    "text_vec_layer([\"Great movie!\", \"This is DiCaprio's best role.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reusing Pretrained Embeddings and Language Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      9\u001b[0m     hub\u001b[38;5;241m.\u001b[39mKerasLayer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                 trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstring, input_shape\u001b[38;5;241m=\u001b[39m[]),\n\u001b[1;32m     11\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswish\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m ])\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnadam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:904\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 904\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    909\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    910\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"my_tfhub_cache\"\n",
    "# https://github.com/tensorflow/hub/issues/70\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                trainable=True, dtype=tf.string, input_shape=[]),\n",
    "    tf.keras.layers.Dense(64, activation=\"swish\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "            metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Encoder-Decoder Network for Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset (pairs of English-Spanish sentences)\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
    "                               extract=True)\n",
    "text = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVe.\n",
      "Go.\tVete.\n",
      "Go.\tVaya.\n",
      "Go.\tVáyase.\n",
      "Hi.\tHola.\n",
      "Run!\t¡Corre!\n",
      "Run.\tCorred.\n",
      "Who?\t¿Quién?\n",
      "Fire!\t¡Fueg\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters, shuffle and split to two separate lists\n",
    "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
    "np.random.shuffle(pairs)\n",
    "sentences_en, sentences_es = zip(*pairs)  # separates the pairs into 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artist always painted alone. => El artista siempre pintaba solo.\n",
      "I drove all night. => Conduje toda la noche.\n",
      "Where is the stop for the airport buses? => Dónde está la parada de los autobuses al aeropuerto?\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(sentences_en[i], \"=>\", sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 10:42:32.783909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Create the TextVectorization layers and adapt them\n",
    "vocab_size = 1000\n",
    "max_length = 50\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first 10 words of the vocabulary, sorted by decreasing frequency\n",
    "text_vec_layer_en.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation sets\n",
    "X_train = tf.constant(sentences_en[:100_000])\n",
    "X_valid = tf.constant(sentences_en[100_000:])\n",
    "X_train_dec  = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
    "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
    "y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
    "y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
       "array([b'The artist always painted alone.', b'I drove all night.',\n",
       "       b'Where is the stop for the airport buses?'], dtype=object)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 50), dtype=int64, numpy=\n",
       "array([[ 10,   1, 100,   1,  79,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  1, 245,   9, 138,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 88,  22,   9,   1,   4,  21,   1,  34, 800,   3,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start building the model\n",
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 50, 128])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
    "# we need the state to pass it to the decoder\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3125/3125 [==============================] - 846s 269ms/step - loss: 2.5075 - accuracy: 0.4587 - val_loss: 2.1135 - val_accuracy: 0.5270\n",
      "Epoch 2/3\n",
      "3125/3125 [==============================] - 876s 280ms/step - loss: 1.8205 - accuracy: 0.5725 - val_loss: 1.7293 - val_accuracy: 0.5945\n",
      "Epoch 3/3\n",
      "3125/3125 [==============================] - 866s 277ms/step - loss: 1.4716 - accuracy: 0.6365 - val_loss: 1.5371 - val_accuracy: 0.6308\n"
     ]
    }
   ],
   "source": [
    "# accuracy does not increase on the GPU sadly\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                        outputs=[Y_proba])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "    model.fit((X_train, X_train_dec), y_train, epochs=3,\n",
    "            validation_data=((X_valid, X_valid_dec), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "    translation = \"\"\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])  # encoder input\n",
    "        X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Biderictional RNNs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 10:36:00.070775: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-05-27 10:36:00.070796: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-05-27 10:36:00.070802: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-05-27 10:36:00.070833: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-27 10:36:00.070851: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_state=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Bidrectional RNN returns four states, so we need to concatenate them\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
    "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 10:44:41.021634: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 325s 102ms/step - loss: 3.5786 - accuracy: 0.3129 - val_loss: 3.2887 - val_accuracy: 0.3311\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 319s 102ms/step - loss: 3.1940 - accuracy: 0.3374 - val_loss: 3.1490 - val_accuracy: 0.3421\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 320s 102ms/step - loss: 3.0636 - accuracy: 0.3474 - val_loss: 3.0845 - val_accuracy: 0.3457\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 323s 103ms/step - loss: 2.9696 - accuracy: 0.3560 - val_loss: 3.0485 - val_accuracy: 0.3507\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 324s 104ms/step - loss: 2.8910 - accuracy: 0.3635 - val_loss: 3.0316 - val_accuracy: 0.3506\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 325s 104ms/step - loss: 2.8214 - accuracy: 0.3706 - val_loss: 3.0188 - val_accuracy: 0.3540\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 324s 104ms/step - loss: 2.7592 - accuracy: 0.3780 - val_loss: 3.0231 - val_accuracy: 0.3557\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 326s 104ms/step - loss: 2.7012 - accuracy: 0.3854 - val_loss: 3.0240 - val_accuracy: 0.3525\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 326s 104ms/step - loss: 2.6474 - accuracy: 0.3924 - val_loss: 3.0381 - val_accuracy: 0.3531\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 325s 104ms/step - loss: 2.5970 - accuracy: 0.3998 - val_loss: 3.0505 - val_accuracy: 0.3521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x365847cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code — completes the model and trains it\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tom [UNK] a mary'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need all the encoder's outputs, so we set return_sequences=True\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normally pass the decoder's hidden state to the attention layer.\n",
    "# But to access the decoder's states at each time step we would need to write\n",
    "# a custom memory cell. So, for simplicity, we just pass the decoder outputs\n",
    "# instead of the decoder's states.\n",
    "# Then we pass the attention layer's output to the output layer as suggested\n",
    "# in the Luong attention paper\n",
    "attention_layer = tf.keras.layers.Attention()\n",
    "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(attention_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 333s 105ms/step - loss: 2.5648 - accuracy: 0.4062 - val_loss: 3.0702 - val_accuracy: 0.3526\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 327s 105ms/step - loss: 2.5102 - accuracy: 0.4143 - val_loss: 3.0878 - val_accuracy: 0.3505\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 329s 105ms/step - loss: 2.4668 - accuracy: 0.4217 - val_loss: 3.1058 - val_accuracy: 0.3505\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 328s 105ms/step - loss: 2.4375 - accuracy: 0.4269 - val_loss: 3.1387 - val_accuracy: 0.3472\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 330s 106ms/step - loss: 2.4176 - accuracy: 0.4299 - val_loss: 3.1446 - val_accuracy: 0.3475\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 332s 106ms/step - loss: 2.3726 - accuracy: 0.4397 - val_loss: 3.1705 - val_accuracy: 0.3470\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 335s 107ms/step - loss: 2.3486 - accuracy: 0.4435 - val_loss: 3.1907 - val_accuracy: 0.3444\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 337s 108ms/step - loss: 2.3245 - accuracy: 0.4482 - val_loss: 3.2111 - val_accuracy: 0.3452\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 338s 108ms/step - loss: 2.2954 - accuracy: 0.4548 - val_loss: 3.2366 - val_accuracy: 0.3415\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 340s 109ms/step - loss: 2.2653 - accuracy: 0.4611 - val_loss: 3.2571 - val_accuracy: 0.3419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3b621aa70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Positional encodings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode word positions using an Embedding layer\n",
    "\n",
    "max_length = 50  # max length in the whole training set\n",
    "embed_size = 128\n",
    "pos_embed_layer = tf.keras.layers.Embedding(max_length, embed_size)\n",
    "batch_max_len_enc = tf.shape(encoder_embeddings)[1]\n",
    "encoder_in = encoder_embeddings + pos_embed_layer(tf.range(batch_max_len_enc))  # the positions of the words in the sentence\n",
    "batch_max_len_dec = tf.shape(decoder_embeddings)[1]\n",
    "decoder_in = decoder_embeddings + pos_embed_layer(tf.range(batch_max_len_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode word positions using sine / cosine functions (fixed encodings)\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_length, embed_size, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert embed_size % 2 == 0, \"embed_size must be even\"\n",
    "        # a set of coordinates to evaluate sin and cos on\n",
    "        p, i = np.meshgrid(np.arange(max_length),\n",
    "                           2 * np.arange(embed_size // 2))\n",
    "        pos_emb = np.empty((1, max_length, embed_size))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10_000 ** (i / embed_size)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10_000 ** (i / embed_size)).T\n",
    "        self.pos_encodings = tf.constant(pos_emb.astype(self.dtype))\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_max_length = tf.shape(inputs)[1]\n",
    "        return inputs + self.pos_encodings[:, :batch_max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embed_layer = PositionalEncoding(max_length, embed_size)\n",
    "encoder_in = pos_embed_layer(encoder_embeddings)\n",
    "decoder_in = pos_embed_layer(decoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 50, 128)\n",
      "(None, 50, 128)\n"
     ]
    }
   ],
   "source": [
    "# Same as the word embeddings matrix shape\n",
    "print(encoder_in.shape)\n",
    "print(decoder_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the transformer architecture's encoder\n",
    "N = 2  # instead of 6\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "n_units = 128  # for the first dense layer in each feedforward block\n",
    "encoder_pad_mask = tf.math.not_equal(encoder_input_ids, 0)[:, tf.newaxis]\n",
    "Z = encoder_in\n",
    "for _ in range(N):\n",
    "    skip = Z\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate\n",
    "    )\n",
    "    Z = attn_layer(Z, value=Z, attention_mask=encoder_pad_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    Z = tf.keras.layers.Dense(n_units, activation=\"relu\")(Z)\n",
    "    Z = tf.keras.layers.Dense(embed_size)(Z)\n",
    "    Z = tf.keras.layers.Dropout(dropout_rate)(Z)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=() dtype=int32 inferred_value=[50] (created by layer 'tf.__operators__.getitem_9')>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_max_len_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle masking in the decoder\n",
    "decoder_pad_mask = tf.math.not_equal(decoder_input_ids, 0)[:, tf.newaxis]\n",
    "causal_mask = tf.linalg.band_part(  # creates a lower triangular matrix\n",
    "    tf.ones((batch_max_len_dec, batch_max_len_dec), tf.bool), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "encoder_outputs = Z  # let's save the encoder's final outputs\n",
    "Z = decoder_in  # the decoder starts with its own inputs\n",
    "for _ in range(N):\n",
    "    skip = Z\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate\n",
    "    )\n",
    "    Z = attn_layer(Z, value=Z, attention_mask=causal_mask & decoder_pad_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate\n",
    "    )\n",
    "    Z = attn_layer(Z, value=encoder_outputs, attention_mask=encoder_pad_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    Z = tf.keras.layers.Dense(n_units, activation=\"relu\")(Z)\n",
    "    Z = tf.keras.layers.Dense(embed_size)(Z)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 980s 310ms/step - loss: 3.0489 - accuracy: 0.3920 - val_loss: 2.3911 - val_accuracy: 0.4812\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 984s 315ms/step - loss: 2.0833 - accuracy: 0.5349 - val_loss: 1.7652 - val_accuracy: 0.5955\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 989s 316ms/step - loss: 1.6705 - accuracy: 0.6100 - val_loss: 1.5591 - val_accuracy: 0.6315\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 996s 319ms/step - loss: 1.5025 - accuracy: 0.6409 - val_loss: 1.4323 - val_accuracy: 0.6593\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 1001s 320ms/step - loss: 1.4083 - accuracy: 0.6587 - val_loss: 1.3693 - val_accuracy: 0.6714\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 990s 317ms/step - loss: 1.3486 - accuracy: 0.6700 - val_loss: 1.3064 - val_accuracy: 0.6843\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 993s 318ms/step - loss: 1.3027 - accuracy: 0.6781 - val_loss: 1.2812 - val_accuracy: 0.6882\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 1013s 324ms/step - loss: 1.2714 - accuracy: 0.6846 - val_loss: 1.2534 - val_accuracy: 0.6952\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 1012s 324ms/step - loss: 1.2412 - accuracy: 0.6895 - val_loss: 1.2337 - val_accuracy: 0.6984\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 1015s 325ms/step - loss: 1.2164 - accuracy: 0.6947 - val_loss: 1.2239 - val_accuracy: 0.7001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x434bc82e0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_proba = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(Z)\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta el [UNK]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like football\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'el tiempo es [UNK] hoy'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"The weather is nice today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face's Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/nikolaoschachampis/Library/Caches/pypoetry/virtualenvs/handson-ml3-DRIwlIAE-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")  # many other tasks are available\n",
    "result = classifier(\"The actors were very convincing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998071789741516}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9896161556243896},\n",
       " {'label': 'NEGATIVE', 'score': 0.9811071157455444}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I am from India.\", \"I am from Iraq.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9933144450187683}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I am from Greece.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9881877303123474}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I am from Patras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'contradiction', 'score': 0.9790192246437073}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"huggingface/distilbert-base-uncased-finetuned-mnli\"\n",
    "classifier_mnli = pipeline(\"text-classification\", model=model_name)\n",
    "classifier_mnli(\"She loves me. [SEP] She loves me not.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokenizer([\"I like soccer. [SEP] We all love soccer!\",\n",
    "                       \"Joe lived for a very long time. [SEP] Joe is old.\"],\n",
    "                       padding=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[ 101, 1045, 2066, 4715, 1012,  102, 2057, 2035, 2293, 4715,  999,\n",
       "         102,    0,    0,    0],\n",
       "       [ 101, 3533, 2973, 2005, 1037, 2200, 2146, 2051, 1012,  102, 3533,\n",
       "        2003, 2214, 1012,  102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-2.1123805 ,  1.1786788 ,  1.4101    ],\n",
       "       [-0.01478534,  1.0962477 , -0.99199367]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(token_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.01619705, 0.43523592, 0.54856706],\n",
       "       [0.22655931, 0.6881727 , 0.08526793]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_probas = tf.keras.activations.softmax(outputs.logits)\n",
    "Y_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 1])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = tf.argmax(Y_probas, axis=1)\n",
    "Y_pred  # 0 = contradiction, 1 = entailment, 2 = neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x6d551e5f0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x6d551e5f0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 48s 48s/step - loss: 2.9976 - accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0884 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "sentences = [(\"Sky is blue\", \"Sky is red\"), (\"I love her\", \"She loves me\")]\n",
    "X_train = tokenizer(sentences, padding=True, return_tensors=\"tf\").data\n",
    "y_train = tf.constant([0, 2])  # contradiction, neutral\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handson-ml3-DRIwlIAE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
